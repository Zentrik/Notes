\section{Metric Spaces}
\subsection{Definitions and Examples}

\begin{question}
    Can we think about convergence in a more general setting? Convergence seemed similar in our 3 settings.

    What do we really need?
\end{question} 
\begin{answer}
    We need a notion of distance.

    In $\mathbb{R}$: distance $x$ to $y$ is $|x-y|$. \\
    In $\mathbb{R}^2$: its $\norm{x - y}$. \\
    For functions: distance $f$ to $g$ is $\sup_{x \in X} |f(x) - g(x)|$ (where this exists, i.e. if $f - g$ bounded).

    The triangle inequality was often important (see the proof of uniqueness of limits).
\end{answer}

\begin{definition}[Metric]
    A $\vocab{metric}$ $d$ is a function $d : X^2 \to \mathbb{R}$ satisfying:
    \begin{itemize}
        \item $d(x, y) \geq 0$ for all $x, y \in X$ with equality iff $x = y$;
        \item $d(x, y) = d(y, x)$ for all $x, y \in X$.
        \item $d(x, z) \leq d(x, y) + d(y, z)$ for all $x, y, z \in X$.
    \end{itemize} 
\end{definition} 

\begin{definition}[Metric Space]
    A $\vocab{metric space}$ is a set $X$ endowed with a metric $d$.
\end{definition} 
We could also define a metric space as an ordered pair $(X, d)$.
If it is obvious what $d$ is, we sometimes write `The metric space $X$ \dots'.

\begin{example}
    $X = \mathbb{R}$, $d(x, y) = |x - y|$
    `The \underline{usual metric} on $\mathbb{R}$'.
\end{example} 

\begin{example}
    $X = \mathbb{R}^n$ with the \underline{Euclidean metric}, $d(x, y) = \norm{x - y} = \sqrt{\sum_{i=1}^{n} (x_i - y_i)^2}$.
\end{example} 

Uniform convergence of functions doesn't quite work: we want $d(f, g) = \sup |f - g|$ but this might not exist if $f - g$ is unbounded.
However, we can do something with appropriate sets of functions.

\begin{example} \label{exm:2.3}
    Let $Y \subset \mathbb{R}$.
    Take $X = B(Y) = \{f : Y \to \mathbb{R} \mid f \text{ bounded}\}$ with the \underline{uniform metric} $d(f, g) = \sup_{x \in Y} |f - g|$.

    Checking triangle inequality:
    \begin{proof}
        Let $f, g, h \in B(Y)$.
        Let $x \in Y$.
        Then \begin{align*}
            |f(x) - h(x)| &\leq |f(x) - g(x)| + |g(x) - h(x)| \\
            &\leq d(f, g) + d(g, h)
            \intertext{Taking $\sup$ over all $x \in Y$}
            d(f, h) \leq d(f, g) + d(g, h).
        \end{align*} 
    \end{proof} 
\end{example} 

\begin{definition}[Subspace]
    Suppose $(X, d)$ a metric space and $Y \subset X$.
    Then $d\mid_{Y^2}$ is a metric on $Y$.
    We say $Y$ with this metric is a \vocab{subspace} of $X$.
\end{definition} 

\begin{example}
    Subspaces of $\mathbb{R}$: any of $\mathbb{Q}, \mathbb{Z}, \mathbb{N}, [0, 1], \dots$ with the usual metric $d(x, y) = |x-y|$.
\end{example} 

\begin{example}
    Recall that a cts function on a closed bounded interval is bounded.
    Define $C([a, b]) = \{f:[a, b] \to \mathbb{R} \mid f \text{ cts}\}$.
    This is a subspace of $B([a, b])$, \cref{exm:2.3}.
    That is $C([a, b])$ is a metric space with the uniform metric $\mathcal{L}(f, g) = \sup_{x \in [a, b]} |f(x) - g(x)|$
\end{example} 

\begin{example}
    The empty metric space $X = \emptyset$ with the empty metric.
\end{example} 

Could maybe define different metrics on the same set:
\begin{example}
    The $\ell_1$ metric on $\mathbb{R}^n$: $d(x, y) = \sum_{i=1}^{n} |x_i - y_i|$.
\end{example} 

\begin{example}
    The $\ell_\infty$ metric on $\mathbb{R}^n$: $d(x, y) = \max_{i} |x_i - y_i|$.\footnote{Proof of triangle inequality similar to \cref{exm:2.3}}
\end{example} 

\begin{example}
    On $C([a, b])$ we can define the $L_1$ metric: $d(f, g) = \int_a^b |f-g|$.
\end{example} 

\begin{example}
    $X = \mathbb{C}$ with 
    \begin{align*}
        d(z, w) = \begin{cases}
            0 & z = w \\
            |z| + |w| & z \neq w.
        \end{cases}.
    \end{align*}

    First two conditions of a metric hold obviously, for triangle inequality we need $d(u, w) \leq d(u, v) + d(v, w)$.

    \begin{enumerate}
        \item If $u = w$, LHS = 0 \checkmark
        \item If $u = v$ or $v = w$ then LHS = RHS \checkmark
        \item If $u, v, w$ distinct:
        \begin{align*}
            LHS &= |u| + |w| \\
            RHS &= |u| + |w| + 2|v| \checkmark
        \end{align*} 
    \end{enumerate} 

    This metric is often called the British Rail metric or SNCF metric, you can think of it as for distinct points you have to travel through the origin.
    {\par 
\centering 
\includegraphics[height=5cm]{02-britishrail} 
    \par}
\end{example} 

\begin{example}[Discrete metric] \label{exm:discrete}
    Let $X$ be any set.
    Define a metric $d$ on $X$ by
    \begin{align*}
        d(x, y) = \begin{cases}
            0 & x = y \\
            1 & x \neq y.
        \end{cases} 
    \end{align*} 

    Easy to check this works.
    This is called the \underline{discrete metric} on $X$.
\end{example} 

\begin{example}[$p$-adic metric]
    Let $\mathbb{X} = \mathbb{Z}$.
    Let $p$ be a prime.
    The \vocab{$p$-adic metric} on $\mathbb{Z}$ is the metric $d$ defined by:
    \begin{align*}
        d(x, y) = \begin{cases}
            0 & x = y \\
            p^{-a} & \text{if $x \neq y$ and $x - y = p^a m$ with $p \nmid m$\footnote{$p^a$ is the largest $a$ s.t. $p^a \mid x - y$}.}
        \end{cases} 
    \end{align*} 
    `Two numbers are close if difference is divisible by a large power of $p$'.

    Only thing we need to check is triangle inequality
    \begin{proof}
        STP: $d(x, z) \leq d(x, y) + d(y, z)$
        \begin{enumerate}
            \item If $x = z$, LHS = 0 \checkmark
            \item If $x = y$ or $y = z$ then LHS = RHS \checkmark
        \end{enumerate} 

        So easy if any two of $x, y, z$ the same so assume $x, y, z$ all distinct.
        Let $x - y = p^a m$ and $y - z = p^b n$ where $p \nmid m, p \nmid n$ and wlog $a \leq b$.
        So $d(x, y) = p^{-a}$ and $d(y, z) = p^{-b}$.

        Now:
        \begin{align*}
            x - z &= (x - y) = (y - z) \\
            &= p^a m + p^b n \\
            &= p^a \underbracket{(m + p^{b - a} n)}_\text{integer} \text{ as $a \leq b$}.
        \end{align*} 
        So $p^a \mid x - z$ so $d(x, z) \leq p^{-a}$.
        But $d(x, y) + d(y, z) \geq d(x, y) = p^{-a}$.
    \end{proof} 
\end{example} 

\begin{definition}[Convergence]
    Let $(X, d)$ be a metric space, let $(x_n)$ be a sequence in $X$ and let $x \in X$.
    We say $(x_n)$ \vocab{converges} to $x$ and write `$x_n \to x$' or `$x_n \to x$ as $n \to \infty$' if
    \begin{align*}
        \forall \; \epsilon > 0 \ \exists \; N \ \forall \; n \geq N \ d(x_n, x) < \epsilon.
    \end{align*} 
\end{definition} 

Equivalently $x_n \to x$ iff $d(x_n, x) \to 0$ in $\mathbb{R}$.

\begin{proposition} \label{prp:15}
    Limits are unique.
    That is, if $(X, d)$ is a metric space, $(x_n)$ a sequence in $X$, $x, y \in X$ with $x_n \to x$ and $x_n \to y$ then $x = y$.
\end{proposition} 

\begin{proof}
    For each $n$, 
    \begin{align*}
        d(x, y) &\leq d(x, x_n) + d(x_n, y) \text{ by triangle inequality} \\
        &\leq d(x_n, x) + d(x_n, y) \text{ by symmetry} \\
        &\to 0 + 0 = 0 \text{ as $d(x_n, x), d(x_n, y) \to 0$}
    \end{align*} 
    So $d(x, y) \to 0$ as $n \to \infty$.
    But $d(x, y)$ is constant so $d(x, y) = 0$ so $x = y$. 
\end{proof} 

\begin{remark}
    This justifies talking about \underline{the} limit of a convergent sequence in a metric space, and writing $x = \lim_{n \to \infty} x_n$ if $x_n \to x$.
\end{remark} 

\begin{remark}[Remarks on definition of convergence in a metric space] \
    \begin{enumerate}
        \item Constant sequences obviously converge. More over, eventually constant sequences converge.
        \item Suppose $(X, d)$ is a metric space and $Y$ is a subspace of $X$.
        Suppose $(x_n)$ is a sequence in $Y$ which converges in $Y$ to $x$.
        Then also $(x_n)$ converges in $X$ to $x$.

        However, converse is false: e.g. in $\mathbb{R}$ with the usual metric then $\frac{1}{n} \to 0$ as $n \to \infty$.
        Consider the subspace $\mathbb{R} \setminus \{0\}$.
        Then $(\frac{1}{n})$ is a sequence in $\mathbb{R} \setminus \{0\}$ but it doesn't converge in $\mathbb{R} \setminus \{0\}$.
        (Why? Suppose $\frac{1}{n} \to x$ in $\mathbb{R} \setminus \{0\}$.
        Then also $\frac{1}{n} \to x$ in $\mathbb{R}$. 
        But $\frac{1}{n} \to 0$ in $\mathbb{R}$ so by uniqueness of limits $x = 0$. But $x \in \mathbb{R} \setminus \{0\}$ and $0 \notin \mathbb{R} \setminus \{0\}$ \Lightning.)
    \end{enumerate} 
\end{remark} 

\begin{example}
    Let $d$ be the Euclidean metric on $\mathbb{R}^n$.
    Exactly as in $\mathbb{R}^2$, we have $x_n \to x$ iff the sequence converges in each coordinate in the usual way in $\mathbb{R}$.

    What about other metrics on $\mathbb{R}^n$?
    E.g. let $d_\infty$ be the uniform metric: $d_\infty(x, y) = \max_i |x_i - y_i|$.
    Which sequences converge in $(\mathbb{R}^n, d_\infty)$?
    $d(x, y) = \sqrt{\sum_{i=1}^{n} (x_i - y_i)^2} \leq \sqrt{\sum_{i=1}^{n} d_\infty(x, y)^2}$ so $d(x,y) \leq \sqrt{n} d_\infty(x,y)$.
    But also $d_\infty(x, y) \leq d(x, y)$ as one of the terms in $d(x, y)$ is $d_\infty^2$.

    Now suppose $(x_n)$ is a sequence in $\mathbb{R}^n$.
    Then $d(x_n, x) \to 0 \iff d(x_n, x) \to 0$.
    So exactly same sequences converge in $(\mathbb{R}^n, d)$ and $(\mathbb{R}^n, d_\infty)$

    What about $\ell_1$ metric $d_1$?
    $d_1(x, y) = \sum_{i=1}^{n} |x_i - y_i|$.
    Similarly, $d_\infty(x, y) \leq d_1(x, y) \leq n d_\infty(x, y)$.
    So again, exactly the same sequences converge in $(\mathbb{R}^n, d_1)$.
\end{example} 

\begin{example}
    Let $X = C([0, 1]) = \{f:[0, 1] \to \mathbb{R} \mid f \text{ continuous}\}$.
    Let $d_\infty$ be the uniform metric on $X$: $d_\infty(f, g) = \sup_{x \in [0, 1]} |f(x) - g(x)|$.
    \begin{align*}
        f_n \to f \text{ in } (X, d_\infty) &\iff d_\infty(f_n, f) \to 0 \\
        &\iff \sup_{x \in [0, 1]} |f_n(x) - f(x)| \to 0 \\
        &\iff f_n \to f \text{ uniformly.}
    \end{align*} 

    We also have $L_1$-metric $d_1$ on $X$: $d_1(f, g) = \int_0^1 |f - g|$.
    Now $d_1(f, g) = \int_0^1 |f-g| \leq \int_0^1 d_\infty(f, g) = d_\infty(f, g)$.
    So similarly to previous example,
    \begin{align*}
        f_n \to f \text{ in } (X, d_\infty) \implies f_n \to f \text{ in } (X, d_1).
    \end{align*} 
    But converse does not hold, i.e. we can find a sequence $(f_n)$ in X s.t. $f_n \to 0$ in $d_1$-metric but $f_n$ doesn't converge in $d_\infty$-metric, i.e. $\int_0^1 |f_n| \to 0$ as $n \to \infty$ but $(f_n)$ does not converge uniformly.
    {\par
    \centering 
    \includegraphics[height=5cm]{02-exm2.14} 
    \par}
    \begin{align*}
        f_n(x) = \begin{cases}
            2nx & x \leq \frac{1}{2n} \\
            2n (\frac{1}{n} - x) & \frac{1}{2n} < x \leq \frac{1}{n} \\
            0 & x > \frac{1}{n}.
        \end{cases} 
    \end{align*}
    Then $d_1(f_n, 0) = \frac{1}{2} \times \frac{1}{n} \times 1 = \frac{1}{2n} \to 0$.
    So in $(X, d_1)$ we have $f_n \to 0$.
    But $f_n$ does not converge uniformly: indeed, $f_n \to 0$ pointwise; if we have uniform convergence then uniform limit is the same as pointwise limit; but $\forall \; n \ f_n(\frac{1}{2n}) = 1$ so $f_n \not\to 0$ uniformly.
\end{example} 

\begin{example}
    Let $(X, d)$ be a discrete metric space; $d(x, y) = \begin{cases}
        0 & x = y \\
        1 & x \neq y
    \end{cases}$.
    When do we have $x_n \to x$ if $(X, d)$?

    Suppose $x_n \to x$, i.e. $\forall \; \epsilon > 0 \ \exists \; N \ \forall \; n \geq N \ d(x_n, x) < \epsilon$.
    Setting $\epsilon = 1$ in this, we can find $N$ s.t. $\forall \; n \geq N \ d(x_n, x) < 1$, i.e. $\forall \; n \geq N \ d(x_n, x) = 0$ i.e. $\forall \; n \geq N \ x_n = x$.
    Thus $(x_n)$ is eventually constant. \\
    But we know in \underline{any} metric space, eventually constant sequences converge.

    So in this space, $(x_n)$ converges iff $(x_n)$ eventually constant.
\end{example} 

\begin{definition}[Continuity]
    Let $(X, d)$ and $(Y, e)$ be metric spaces and let $f : X \to Y$.
    \begin{enumerate}
        \item Let $a \in X$ and $b \in Y$.
        We say $f(x) \to b$ as $x \to a$ if $\forall \; \epsilon > 0 \ \exists \; \delta > 0 \ \forall \; x \in X \ 0 < d(x, a) < \delta \implies e(f(x), b) < \epsilon$. \label{def:con1}
        \item Let $a \in X$.
        We say $f$ is \vocab{continuous} at $a$ if $f(x) \to f(a)$ as $x \to a$. \\
        That is: $\forall \; \epsilon > 0 \ \exists \; \delta > 0 \ \forall \; x \in X \ d(x, a) < \delta \implies e(f(x), f(a)) < \epsilon$.
        \item If $\forall \; a \in X$ $f$ is continuous at $a$ we say $f$ is a \vocab{continuous} function or simply $f$ is \vocab{continuous}.
        \item We say $f$ is \vocab{uniformly continuous} if $\forall \; \epsilon > 0 \ \exists \; \delta > 0 \ \forall \; x,y \in X \ d(x, y) < \delta \implies e(f(x), f(y)) < \epsilon$
        \item Suppose $W \subset X$.
        We say $f$ is \vocab{continuous on $W$} (respectively \vocab{uniformly continuous on $W$}) if the function $f\mid_W$ is continuous (resp. uniformly continuous), as a function from $W \to Y$ where we are now thinking of $W$ as a subspace of $X$. \label{def:con5}
    \end{enumerate} 
\end{definition} 

% \begin{definition}[Uniform continuity]
%     We say $f$ is \vocab{uniformly continuous} if $\forall \; \epsilon > 0 \ \exists \; \delta > 0 \ \forall \; x,y \in X \ d(x, y) < \delta \implies e(f(x), f(y)) < \epsilon$
% \end{definition} 

\begin{remark}
    \begin{enumerate}
        \item Don't have a nice rephrasing of \cref{def:con1} in terms of similar concepts in the reals.
        We would want to write `$e(f(x), b) \to 0$ as $d(x, a) \to 0$'.
        But this is meaningless, we haven't defined such a concept in the reals.
        \item \Cref{def:con1} says nothing about what happens at the point $a$ itself. 
        E.g. let $f : \mathbb{R} \to \mathbb{R}, f(x) = \begin{cases}
            1 & x = 0 \\
            0 & x \neq 0
        \end{cases}$.
        Then $f(x) \to 0$ as $x \to 0$ (but $f(0) \neq 0$ so $f$ is not continuous at $0$). \\
        If we have $f$ cts then $d(x, a) = 0 \implies x = a \implies f(x) = f(a) \implies e(f(x), f(a)) = 0$.
        So we can drop the `$0 <$' from definition of continuity.
        \item We can rewrite \cref{def:con5}: $f$ is continuous on $W$ iff $f\mid_W$ is a continuous function $f\mid_W : W \to Y$ thinking of $W$ as a subspace of $X$.
        That is: $\forall \; a \in W \ \forall \; \epsilon > 0 \ \exists \; \delta > 0 \ \forall \; x \in X \ d(x, a) < \delta \implies e(f(x), f(a)) < \epsilon$.
        In particular, note the subtlety that this \underline{only} mentions points of $W$.
        So under this definition, e.g. $f : \mathbb{R} \to \mathbb{R}, f(x) = \begin{cases}
            1 & x \in [0, 1] \\
            0 & x \notin [0, 1]
        \end{cases}$ then $f\mid_{[0, 1]}$ is cts.
        But $f$ is not cts at points $0, 1$.
    \end{enumerate} 
\end{remark} 

\begin{proposition} \label{prp:16}
    Let $(X, d), (Y, e)$ be metric spaces, $f : X \to Y$ and $a \in X$.
    Then $f$ is continuous at $a$ iff whenever $(x_n)$ is a sequence in $X$ with $x_n \to a$ then $f(x_n) \to f(a)$.
\end{proposition} 

\begin{proof}
    ($\implies$): Suppose $f$ is cts at $a$.
    Let $(x_n)$ be a sequence in $X$ with $x_n \to a$.
    Let $\epsilon > 0$.
    As $f$ cts at $a$ we can find $\delta > 0$ s.t. $\forall \; x \in X$ s.t. $d(x, a) < \delta \implies e(f(x), f(a)) < \epsilon$.
    As $x_n \to x$ we can find $N$ s.t. $n \geq N \implies d(x_n, a) < \delta$.
    Let $n \geq N$ then $d(x_n, a) < \delta$ so $e(f(x_n), f(a)) < \epsilon$.
    Hence $f(x_n) \to f(a)$.

    ($\Longleftarrow$): Suppose $f$ is not cts at $a$.
    Then there is some $\epsilon > 0$ s.t. $\forall \; \delta > 0 \ \exists \; x \in X$ with $d(x, a) < \delta$ but $e(f(x), f(a)) \geq \epsilon$.
    Now take $\delta = \frac{1}{n}$ we obtain a sequence $(x_n)$ with, for each $n$ $d(x_n, a) < \frac{1}{n}$ but $e(f(x_n), f(a)) > \epsilon$.
    Hence $x_n \to a$ but $f(x_n) \not\to f(a)$.
\end{proof} 

\begin{proposition} \label{prp:17}
    Let $(W, c), (X, d), (Y, e)$ be metric spaces, left $f: W \to X$, let $g: X \to Y$ and let $a \in W$.
    Suppose $f$ is cts at $a$ and $g$ is cts at $f(a)$.
    Then $g \circ f$ is cts at $a$.
\end{proposition} 

\begin{proof}
    Let $(x_n)$ be a sequence in $W$ with $x_n \to a$.
    Then by \cref{prp:16}, $f(x_n) \to f(a)$ and so also $g(f(x_n)) \to g(f(a))$.
    So by \cref{prp:16} $g \circ f$ cts at a. 
\end{proof} 

\begin{example} \label{exm:con1}
    In $\mathbb{R} \to \mathbb{R}$ with the usual metric, this is the same definition as when we defined continuity directly for $\mathbb{R}$ only.
    So we already have lots of cts fcns $\mathbb{R} \to \mathbb{R}$: polynomials, $\sin$, $e^x$, \dots
\end{example} 

\begin{example}
    Constant functions are continuous.
    Also if $X$ is any metric space and $f: X \to X$ by $f(x) = x$ for all $x \in X$ (the \underline{indentity function}) then that is continuous.
\end{example} 

\begin{example}[Projection Maps]
    Consider $\mathbb{R}^n$ with the usual metric and $\mathbb{R}$ with the usual metric.
    The \vocab{projection maps} $\pi_i: \mathbb{R}^n \to \mathbb{R}$ given by $\pi_i(x) = x_i$ are continuous. 
    
    (Why? We've seen convergence in $\mathbb{R}^n$ of sequences is the same as convergence in each coordinate. 
    Let's denote a sequence in $\mathbb{R}^n$ by $(x^{(m)})_{m \geq 1}$. So e.g. $x^{(3)}_5$ is the $5$th coord of the $3$rd term.
    We know $x^{(m)} \to x$ iff for each $i$ $x_i^{(m)} \to x_i$, i.e. for each $i$ $\pi_i(x^{(m)}) \to \pi_i(x)$.
    Then we can use \cref{prp:16})

    Similarly, suppose $f_1, \dots, f_n: \mathbb{R} \to \mathbb{R}$
    Let $f: \mathbb{R} \to \mathbb{R}^n$ defined by $f(x) = (f_1(x), \dots, f_n(x))$.
    Then $f$ is cts at a point iff all of $f_1, \dots, f_n$ are.
    Using these facts \cref{exm:con1} and \cref{prp:17}, we have many cts fcns $\mathbb{R}^n \to \mathbb{R}^m$.
    E.g. $f: \mathbb{R}^3 \to \mathbb{R}^2, f(x, y, z) = (e^{-x} \sin y, 2x \cos z)$ is cts. (Why? write $w = (x, y, z) \in \mathbb{R}^3$, we have $f_1(w) = e^{-\pi_1(w)} \sin \pi_2(w)$ and $f_2(w) = 2 \pi_1(w) \cos \pi_3(w)$.
    So $f_1, f_2$ cts so $f$ cts.)
\end{example} 

\begin{example}
    Recall that if we have the Euclidean metric, the $l_1$ or $l_\infty$ metric on $\mathbb{R}^n$ then the convergent sequences are the same.
    So by \cref{prp:16}, the ctf fcns $X \to \mathbb{R}^n$ or from $\mathbb{R}^n \to Y$ are the same with each of these three metrics.
\end{example} 

\begin{example}
    Let $(X, d)$ be the discrete metric space, \cref{exm:discrete}, and let $(Y, e)$ be any metric space.
    Which functions $f : X \to Y$ are cts?
    Suppose $a \in X$ and $(x_n)$ a sequence in $X$ with $x_n \to a$.
    Then $(x_n)$ is eventually constant, i.e. for sufficiently large $n$ $x_n = a$ and so $f(x_n) = f(a)$.
    So $f(x_n) \to f(a)$.

    Hence \underline{every} function on a discrete metric space is cts.
\end{example} 

\subsection{Completeness}
\begin{question}
    In \cref{sec:1} we saw a version of GPC held in each of the three examples we considered. 
    Does GPC hold in a general metric space?
\end{question} 

\begin{definition}[Cauchy Sequences]
    Let $(X, d)$ be a metric space and let $(x_n)$ be a sequence in $X$.
    We say $(x_n)$ is \vocab{Cauchy} if $\forall \; \epsilon > 0 \ \exists \; N \ \forall \; m, n \geq N \ d(x_m, x_n) < \epsilon$.
\end{definition} 

\begin{theorem}
    $(x_n)$ convergent $\implies (x_n)$ Cauchy.
\end{theorem} 
\begin{proof}
    Left as an exercise.
\end{proof} 

But converse is not true in general.

\begin{example} \label{exm:rnot0}
    Let $X = \mathbb{R} \setminus \{0\}$ with the usual metric and $x_n = \frac{1}{n}$.
    We say previously that $(x_n)$ does not converge. \\
    Note that $X$ is a subspace of $\mathbb{R}$.
    In $\mathbb{R}$ $(x_n)$ is convergent $(x_n \to 0)$ so $(x_n)$ is Cauchy in $\mathbb{R}$ so $(x_n)$ is Cauchy in $X$.
\end{example} 

\begin{example}
    $\mathbb{Q}$ with the usual metric.
    Let $x_n$ be $\sqrt{2}$ to $n$ decimal places.
    This converges in $\mathbb{R}$ so is Cauchy in $\mathbb{Q}$ but clearly doesn't converge in $\mathbb{Q}$.
\end{example} 

\begin{definition}[Completeness]
    Let $(X, d)$ be a metric space.
    We say $X$ is \vocab{complete} if every Cauchy sequence in $X$ converges.
\end{definition} 

\begin{example}
    \Cref{exm:rnot0} says $\mathbb{R} \setminus \{0\}$ with the usual metric is not complete. \\
    Similarly $\mathbb{Q}$ with usual metric is not complete.
\end{example} 

\begin{example}
    GPC says $\mathbb{R}$ with the usual metric is complete.
\end{example} 

\begin{example}
    GPC for $\mathbb{R}^n$ says $\mathbb{R}^n$ with Euclidean metric is complete.
\end{example} 

\begin{example} \label{exm:gpuc}
    GPUC, \cref{thm:7}, (almost) says if $X \subset \mathbb{R}$ and $B(X) = \{f : X \to \mathbb{R} \mid f \text{ is bounded}\}$ with the uniform norm then $B(X)$ is complete.
\end{example} 

\begin{proof}
    Let $(f_n)$ be a Cauchy sequence in $B(X)$.
    Then $(f_n)$ is uniformly Cauchy so by GPUC is uniformly convergent.
    That is $f_n \to f$ uniformly for some $f: X \to \mathbb{R}$.
    As $f_n \to f$ uniformly we know $f_n - f$ is bounded for $n$ suff. large.
    Take such an $n$, then $f_n - f$ and $f_n$ are bounded so $f = f_n - (f_n  - f)$ is bounded.
    That is, $f \in B(X)$.
    Finally, $f_n \to f$ uniformly and $d(f_n, f) \to 0$, i.e. $f_n \to f$ in $(B(X), d)$.
\end{proof} 

\begin{remark}
    In many ways, this is typical of a proof that a given space $(X, d)$ is complete:
    \begin{enumerate}
        \item Take $(x_n)$ Cauchy in $X$;
        \item Construct/ find a putative limit object $x$ where it seems $(x_n)$ converges to $x$ in some sense;
        \item Show $x \in X$,
        \item Show $x_n \to x$ in metric space $(X, d)$ i.e. that $d(x_n, x) \to 0$.
    \end{enumerate} 
    This is often tricky/ fiddly/ annoying/ repetitive/ boring.
    But we need to take care as for example, it's tempting to talk about $d(x_n, x)$ while doing (ii) or (iii); but makes no sense to write `$d(x_n, x)$' until we have completed (iii) as $d$ is only defined on $X^2$ (if $x \notin X$ then can't use $d$).
\end{remark} 

\begin{example}
    If $[a, b]$ is a closed interval then $C([a, b])$ with uniform norm $d$ is complete.
\end{example} 

\begin{proof}
    (i): Let $(f_n)$ be a Cauchy sequence in $C([a, b])$. \\
    (ii): We know $C([a, b])$ is a subspace of $B([a, b])$ with uniform metric.
    We know $B([a, b])$ is complete by \cref{exm:gpuc} and $(f_n)$ is a Cauchy sequence in $B([a, b])$ so in $B([a, b])$, $f_n \to f$ for some $f$. \\
    (iii) Each $f_n$ is cts and $f_n \to f$ uniformly so $f$ is cts, i.e. $f \in C([a, b])$. \\
    (iv) Finally, each $f_n \in C([a, b])$, $f \in C([a, b])$ and $f_n \to f$ uniformly so $d(f_n, f) \to 0$.
\end{proof} 

This generalises:
\begin{definition}[Closed Metric Space]
    Let $(X, d)$ be a metric space and $Y \subset X$.
    We say $Y$ is \vocab{closed} if whenever $(x_n)$ a sequence in $Y$ with $x_n \to x \in X$ then $x \in Y$.
\end{definition} 

\begin{proposition} \label{prp:18}
    A closed subset of a complete metric space is complete.
\end{proposition} 

\begin{remark}
    This \underline{does} make sense: if $Y \subset X$ then $Y$ is itself a metric space or a subspace of $X$ so we can say e.g. `$Y$ is complete' to mean the metric space $Y$ (as a subspace of $X$) is complete.

    We could do exactly the same with any other properties of metric spaces we define.
\end{remark} 

\begin{proof}
    Let $(X, d)$ be a metric space and $Y \subset X$ with $X$ complete and $Y$ closed.
    (i): Let $(x_n)$ be a Cauchy sequence in $Y$. \\
    (ii): Now $(x_n)$ is a Cauchy sequence in $X$ so by completeness $x_n \to x$ in $X$ for some $x \in X$. \\
    (iii) $Y \subset X$ is closed so $x \in Y$. \\
    (iv) Finally we now have each $x_n \in Y, x \in Y$ and $x_n \to x$ in $X$, so $d(x_n, x) \to 0$ so $x_n \to x$ in $Y$.
\end{proof} 

\begin{example}
    Define $\ell_1 = \{ (x_n)_{n \geq 1} \in \mathbb{R}^\mathbb{N} \mid \sum_{n=1}^{\infty} |x_n| \text{ converges} \}$.
    Define a metric $d$ on $\ell_1$ by $d((x_n), (y_n)) = \sum_{n=1}^{\infty} |x_n - y_n|$.

    Note we have $\sum |x_n|, \sum |y_n|$ converge as we are in $\ell_1$.
    For each $n$ $|x_n - y_n| \leq |x_n| + |y_n|$ so by comparison test $\sum |x_n - y_n|$ converges.
    So $d$ is well-defined.
    Easy to check $d$ is a metric on $\ell_1$.
    Then $(\ell_1, d)$ is complete.
\end{example} 

\begin{proof}
    (i): Let $(x^{(n)})_{n \geq 1}$ be a Cauchy sequence in $\ell_1$, so for each $n$ $(x^{(n)}_i)_{i \geq 1}$ is a sequence in $\mathbb{R}$ with $\sum_{i=1}^{\infty} |x_i^{(n)}|$ convergent. \\
    % (ii) For each $n$, $(x_i^{(n)})_{i \geq 1}$ is a Cauchy sequence in $\mathbb{R}$ since if $y, z \in \ell_1$ then $|y_i - z_i| \leq d(y, z)$.
    % But $\mathbb{R}$ is complete, so for each $n$ we 
    (ii) For each $i$, $(x_i^{(n)})_{n \geq 1}$ is a Cauchy sequence in $\mathbb{R}$, since if $y, z \in \ell_1$ then $|y_i - z_i| \leq d(y, z)$.
    But $\mathbb{R}$ is complete, so for each $i$ we can find $x_i \in \mathbb{R}$ s.t. $x_i^{(n)} \to x_i$ as $n \to \infty$. \\
    Let $x = (x_1, x_2, \dots) \in \mathbb{R}^\mathbb{N}$. \\
    (iii) We next show $x \in \ell_1$, i.e. that $\sum_{i=1}^{\infty} |x_i|$ converges.

    Given $y \in \ell_1$, define $\sigma(y) = \sum_{i=1}^{\infty} |y_i|$, i.e. $\sigma(y) = d(y, z)$ where $z$ is the constant zero sequence. \\
    We now have, for any $m, n$
    \begin{align*}
        \sigma(x^{(m)}) &= d(x^{(m)}, z) \\
        &\leq d(x^{(m)}, x^{(n)}) + d(x^{(n)}, z) \\
        &= d(x^{(m)}, x^{(n)}) + \sigma(x^{(n)}) 
    \end{align*} 
    So $\sigma(x^{(m)}) - \sigma(x^{(n)}) \leq d(x^{(m)}, x^{(n)})$.
    Similarly, for any $m, n$ $\sigma(x^{(n)}) - \sigma(x^{(m)}) \leq d(x^{(m)}, x^{(n)})$ and so $|\sigma(x^{(m)}) - \sigma(x^{(n)})| \leq d(x^{(m)}, x^{(n)})$.
    Hence $(\sigma(x^{(m)}))_{m \geq 1}$ is a Cauchy sequence in $\mathbb{R}$, and so by GPC converges, say $\sigma(x^{(m)}) \to K$ as $m \to \infty$.

    \begin{claim}
        For any $I \in \mathbb{N}$, $\sum_{i=1}^{I} |x_i| \leq K + 2$.
    \end{claim}
    
    \begin{proof}
        As $\sigma(x^{(n)}) \to K$ as $n \to \infty$ we can find $N_1$ s.t. $n \geq N_1 \implies \sum_{i=1}^{\infty} |x_i^{(n)}| \leq K + 1$.
        Also, $n \geq N_1 \implies \sum_{i=1}^{I} |x_i^{(n)}| \leq K + 1$ (as each term non-negative).

        Next, for each $i \in \{1, 2, \dots, I\}$ we have $x_i^{(n)} \to x_i$ as $n \to \infty$.
        So we can find $N_2$ s.t. $n \geq N_2 \implies \forall \; i \in \{1, \dots, I\} \ |x_i^{(n)} - x_i| < I\inv$.

        Now let $n = \max (N_1, N_2)$ then $\sum_{i=1}^{I} |x_i| \leq \sum_{i=1}^{I} |x_i^{(n)}| + \sum_{i=1}^{I} |x_i^{(n)} - x_i| \leq K + 1 + I (I\inv) = K + 2$.
    \end{proof} 

    Now the partial sums of $\sum |x_i|$ are increasing and bounded above so $\sum |x_i|$ converges.
    That is $x \in \ell_1$. 

    (iv) Finally, need to check $x^{(n)} \to x$ as $n \to \infty$ in $\ell_1$, i.e. that $d(x^{(n)}, x) \to 0$ as $n \to \infty$. \\
    We have, for all $n, I$:
    \begin{align*}
        d(x^{(n)}, x) &= \sum_{i=1}^{\infty} |x_i^{(n)} - x_i| &\\
        &\leq \sum_{i=1}^{I} |x_i^{(n)} - x_i| + \sum_{i=I+1}^{\infty} |x_i^{(n)}| + \sum_{i=I + 1}^{\infty} |x_i|.
    \end{align*}
    Let $\epsilon>0$.
    We know $\sum |x_i|$ convergent (as $x \in \ell_1$) so we can pick $I_1$ s.t. $\sum_{i=I_1+1}^{\infty} |x_i| < \epsilon$. \\
    As $(x^{(n)})$ is Cauchy, we can find $N_1$ s.t. $m, n \geq N_1 \implies d(x^{(m)}, x^{(n)}) < \epsilon$.
    As $\sum_i |x_i^{(N_1)}|$ converges, we can find $I_2$ s.t. $\sum_{i=I_2+1}^{\infty} |x_i^{(N_1)}| < \epsilon$.
    Then
    \begin{align*}
        n \geq N_1 \implies \sum_{i=I_2 + 1}^{\infty} |x_i^{(n)}| &\leq \sum_{i=I_2 + 1}^{\infty} |x_i^{(N_1)}| + \sum_{i=I_2 + 1}^{\infty} |x_i^{(n)} - x_i^{(N_1)}| \\
        &< \epsilon + d(x^{(n)}, x^{(N_1)}) \\
        &< 2\epsilon.
    \end{align*} 
    Let $I = \max(I_1, I_2)$.
    For each $i = 1, 2, \dots, I$ we have $|x_i^{(n)} - x_i| \to 0$ as $n \to \infty$, so $\sum_{i=1}^{I} |x_i^{(n)} - x_i| \to 0$ as $n \to \infty$.
    Hence we can find $N_2$ s.t $n \geq N_2 \implies \sum_{i=1}^{I} |x_i^{(n)} - x_i| < \epsilon$.
    Let $N = \max(N_1, N_2)$ and let $n \geq N$.
    Then \begin{align*}
        d(x^{(n)}, x) &\leq \sum_{i=1}^{I} |x_i^{(n)} - x_i| + \sum_{i=I+1}^{\infty} |x_i^{(n)}| + \sum_{i=I+1}^{\infty} |x_i| \\
        &\leq \sum_{i=1}^{I} |x_i^{(n)} - x_i| + \sum_{i=I_2 + 1}^\infty |x_i^{(n)}| + \sum_{i=I_1 + 1}^{\infty} |x_i| \\
        &< \epsilon + 2\epsilon + \epsilon = 4\epsilon  
    \end{align*} 
    Hence $d(x^{(n)}, x) \to 0$ as $n \to \infty$, i.e. $x^{(n)} \to x$ in $\ell_1$. \\
    Hence $\ell_1$ is complete.
\end{proof} 

Now we will move on to main theorem of completeness.

\begin{definition}[Contraction mapping]
    Let $(X, d)$ be a metric space and $f:X \to X$.
    We say $f$ is a \vocab{contraction} if $\exists \; \lambda \in [0, 1)$ s.t. $\forall \; x, y \in X \ d(f(x), f(y)) \leq \lambda d(x, y)$.
\end{definition} 

\begin{theorem}[The Contraction Mapping Theorem] \label{thm:19}
    Let $(X, d)$ be a complete, non-empty metric space and $f: X \to X$ a contraction.
    Then $f$ has a unique fixed point.
\end{theorem} 

\begin{proof}
    Let $\lambda \in [0, 1)$ satisfy $\forall \; x, y \in X \ d(f(x), f(y)) \leq \lambda d(x, y)$. \\
    Let $x_0 \in X$.
    Recursively define $x_n = f(x_{n - 1})$ for $n \geq 1$.
    Let $\Delta = d(x_0, x_1)$.
    Then, by induction $d(x_n, x_{n+1}) \leq \lambda^n \Delta$ for all $n$. \\
    Now suppose $N \leq m < n$.
    Then
    \begin{align*}
        d(x_m, x_n) &\leq \sum_{i=m}^{n-1} d(x_i, x_{i + 1}) \\
        &\leq \sum_{i=m}^{n-1} \lambda^i \Delta \\
        &\leq \sum_{i=N}^{\infty} \lambda^i \Delta \\
        &= \frac{\lambda^N \Delta}{1 - \lambda} \to 0 \text{ as $N \to \infty$}.
    \end{align*}
    So $\forall \; \epsilon > 0 \ \exists \; N \ \forall \; m, n \geq N \ d(x_m, x_n) < \epsilon$ (i.e. we take $N$ s.t. $\frac{\lambda^N \Delta}{1 - \lambda} < \epsilon$).
    Thus $(x_n)$ is Cauchy, so by completeness converges, say $x_n \to x \in X$.
    But also $x_n = f(x_{n-1}) \to f(x)$ as $f$ continuous\footnote{follows immediately from definition of contraction mapping (e.g. let $\delta = \epsilon$ in definition of continuity).}.
    So by uniqueness of limits, $f(x) = x$.

    Suppose also $f(y) = y$ for some $y \in X$.
    Then $d(x, y) = d(f(x), f(y)) \leq \lambda d(x, y)$ with $\lambda < 1$.
    So $d(x, y) = 0$ so $x = y$.
\end{proof} 

\begin{remark} \
    \begin{enumerate}
        \item Why is $f$ cts? We have, for all $x, y \in X$ $d(f(x), f(y)) \leq d(x, y)$.
        So $\forall \; \epsilon > 0$, $d(x, y) < \epsilon \implies d(f(x), f(y)) < \epsilon$.
        (Indeed, this shows $f$ is uniformly continuous.)
        \item We have proved more than claimed.
        Not only does $f$ have a unique fixed point, but starting from \underline{any} point of the space and repeatedly apply $f$ then the resulting sequence converges to the fixed point.
        In fact, the speed of convergence is exponential.
    \end{enumerate} 
\end{remark} 

\begin{example}[Application]
    Suppose we want to numerically approximate the solution to $\cos x = x$.
    Any root must lie in $[-1, 1]$.
    Consider metric space $X = [-1, 1]$ with usual metric.
    $X$ is a closed subset of a complete space $\mathbb{R}$ so is complete.
    Obviously $X$ is non-empty.
    Think of $\cos : [-1, 1] \to [-1, 1]$.
    Suppose $x, y \in [-1, 1]$.
    \begin{align*}
        |\cos x - \cos y| &= |x-y| |\cos'z| \text{ for some $z \in [-1, 1]$ by MVT} \\
        & |x-y| |-\sin'z| \\
        &\leq |x-y| \sin 1
    \end{align*} 
    But $0 \leq \sin 1 < 1$ so $\cos$ is a contraction of $[-1, 1]$.
    So by \nameref{thm:19}, $\cos$ has a unique fixed point in $[-1, 1]$.
    That is $\cos x = x$ has a unique solution.

    How do we find it numerically?
    Use remark 2, we will have rapid convergence to the root.
\end{example} 

We will see two major applications of CMT (\nameref{thm:19}) later.

\subsection{Sequential Compactness}
Recall BW for $\mathbb{R}^n$ says a bounded sequence in $\mathbb{R}^n$ has a convergent subsequence.

\begin{definition}[Bounded]
    Let $(X, d)$ be a metric space.
    We say $X$ is \vocab{bounded} if
    \begin{align*}
        \exists \; M \in \mathbb{R} \ \forall \; x, y \in X \ d(x, y) \leq M.
    \end{align*} 
\end{definition} 

\begin{remark}
    Easy to check by triangle inequality that $X$ bounded $\iff (X = \emptyset \text{ or } \exists \; M \in \mathbb{R},\ x \in X \text{ s.t. } \forall \; y \in X \ d(x, y) \leq M)$.
    So definition agrees with earlier definition for subsets of $\mathbb{R}^n$.
\end{remark} 

\begin{definition}[Closed subspace]
    Let $(X, d)$ be a metric space and $Y \subset X$.
    We say $Y$ is \vocab{closed} in $X$ if whenever $(x_n)$ is a sequence in $Y$ with, in X, $x_n \to x \in X$ then $x \in Y$.
\end{definition} 

\begin{definition}[Sequentially Compact]
    A metric space is \vocab{sequentially compact} if every sequence has a convergent subsequence.
\end{definition}  

BW for $\mathbb{R}^n$ is essentially the following:
\begin{theorem} \label{thm:20}
    Let $X \subset \mathbb{R}^n$ with the Euclidean metric.
    Then $X$ is sequentially compact iff $X$ is closed and bounded.
\end{theorem} 

\begin{proof}
    ($\Longleftarrow$) Suppose $X$ is closed and bounded.
    Let $(x_n)$ be a sequence in $X$.
    Then $(x_n)$ is a bounded sequence in $\mathbb{R}^n$ so by BW, in $\mathbb{R}^n$, $x_{n_j} \to x$ for some $ x \in \mathbb{R}^n$ and some subsequence $(x_{n_j})$ of $(x_n)$. \\
    As $X$ is closed, $x \in X$.
    Hence the subsequence $(x_{n_j})$ converges in $X$.
    So $X$ is sequentially compact.

    ($\implies$) Suppose $X$ is not closed.
    Then we can find a sequence $(x_n)$ in $X$ s.t. in $\mathbb{R}^n$ $x_n \to x \in \mathbb{R}^n$ with $x \notin X$.
    Now any subsequence $(x_{n_j}) \to x$ in $\mathbb{R}^n$.
    But $x \notin X$ so by uniqueness of limits $(x_{n_j})$ does not converge in $X$.
    So $X$ is not sequentially compact.

    Suppose instead $X$ is not bounded.
    Then we can find a sequence $(x_n)$ in $X$ with $\forall \; n \ \norm{x_n} \geq n$, i.e. $\norm{x_n} \to \infty$ as $n \to \infty$.
    Suppose we have a subsequence $x_{n_j} \to x \in X$.
    Then $\norm{x_{n_j}} \to \norm{x}$ but $\norm{x_{n_j}} \to \infty$ \Lightning.
    So, again, $X$ is not sequentially compact.
\end{proof} 

\begin{remark}
    Does this hold in a general metric space?
    Obviously not: e.g. in $\mathbb{R} \setminus \{0\}$ with the usual metric, the set $[-1, 0) \cup (0, 1]$ is closed and bounded but the sequence $(\frac{1}{n})_{n \geq 1}$ has no convergent subsequence.
\end{remark} 


\underline{Problem}: Space is not complete.
Maybe complete and bounded $\implies$ sequentially compact?

Even this doesn't work.
Recall example from section 1:
Let $X = \{f \in B(\mathbb{R}) :  \sup_{x \in \mathbb{R}} |f(x)| \leq 1\}$ with uniform metric.
Then $X$ is complete (closed subset of a complete space $B(\mathbb{R})$) and bounded (if $f, g \in X$ then $d(f, g) \leq 2$).
But consider $f_n(x) = \begin{cases}
    1 & x = n \\
    0 & x \neq n
\end{cases}$.
Then $f_n$ is a sequence in $X$ but $\forall \; m, n$ $m \neq n \implies d(f_m, f_n) = 1$.
So $(f_n)$ cannot have a convergent subsequence.

\underline{Problem}: $X$ is `too big'.

We need a stronger concept of boundedness.

\begin{definition}[Totally Bounded]
    Let $(X, d)$ be a metric space.
    We say $X$ is \vocab{totally bounded} if $\forall \; \delta > 0$ we can find a \underline{finite} subset $A \subset X$ s.t. $\forall \; x \in X \ \exists \; a \in A \ d(x, a) < \delta$.
\end{definition} 

\begin{theorem} \label{thm:21}
    A metric space is sequentially compact iff it is complete and totally bounded.
\end{theorem} 

\begin{proof}
    $(\Longleftarrow)$: Suppose the metric space $(X, d)$ is complete and totally bounded.
    Let $(x_n)_{n \geq 1}$ be a sequence in $X$. \\
    As $X$ is totally bounded, we can find finite $A_1 \subset X$ s.t. $\forall \; x \in X \ \exists \; a \in A_1 \ d(x, a) < 1$.
    In particular, there is an infinite set $N_1 \subset \mathbb{N}$ and a point $a_1 \in A_1$ s.t. $\forall \; n \in N_1 \ d(x_n, a_1) < 1$.
    Hence $\forall \; m, n \in N_1 \ d(x_m, x_n) < 2$. \\
    Similarly, we can find finite $A_2 \subset X$ s.t. $\forall \; x \in X \ \exists \; a \in A_2 \ d(x, a) < \frac{1}{2}$.
    In particular, there is an infinite $N_2 \subset N_1$ s.t. $\forall \; n \in N_2 \ d(x_n, a_2) < \frac{1}{2}$ and thus $\forall \; m, n \in N_2 \ d(x_m, x_n) < 1$. \\
    Keep going.
    We get a sequence $N_1 \supset N_2 \supset N_3 \dots$ of infinite subsets of $\mathbb{N}$ s.t. $\forall \; i \ \forall \; m, n \in N_i \implies d(x_m, x_n) < \frac{2}{i}$. \\
    Now pick $n_1 \in N_1$.
    Then pick $n_2 \in N_2$ with $n_2 > n_1$.
    Then pick $n_i \in N_i$ with $n_i > n_{i - 1}$. \\
    We obtain a subsequence $(x_{n_j})$ of $(x_n)$ s.t. $\forall \; j \ x_{n_j} \in N_j$.
    Thus if $i \leq j$ then $x_{n_i}, x_{n_j} \in N_i$ and so $d(x_{n_i}, x_{n_j}) < \frac{2}{i}$.
    Hence $(x_{n_j})$ is a Cauchy sequence and hence by completeness, converges.
    Thus $X$ is sequentially compact.

    ($\implies$) Suppose $X$ is not complete.
    Then $X$ has a Cauchy sequence $(x_n)$ which doesn't converge.
    Suppose we have a convergent subsequence, say $x_{n_j} \to x$.
    Then $x_n \to x$ (left as an exercise, same as in gpc for $\mathbb{R}$) \Lightning.

    Suppose instead $X$ not totally bounded.
    Then there is some $\delta > 0$ s.t. whenever $A \subset X$ is finite $\exists \; x \in X \ \forall \; a \in A \ d(x, a) < \delta$.
    So pick $x_1 \in X$, pick $x_2 \in X$ s.t. $d(x_1, x_2) \geq \delta$, pick $x_3 \in X$ s.t. $d(x_1, x_3) \geq \delta$ and $d(x_2, x_3) \geq \delta$ \dots
    We get a sequence $(x_n) \in X$ s.t. $\forall \; i, j \ i \neq j \implies d(x_i, x_j) \geq \delta$.
    Hence $(x_n)$ has no convergent subsequence.
\end{proof} 

\begin{exercise}
    A cts fcn on a sequentially compact metric space is uniformly compact.
    If the fcn is real-valued then it's bounded and attains its bounds.
\end{exercise} 

\subsection{The Topology of Metric Spaces}
Theme of section 2: to generalise convergence/ continuity, all we need is a distance.

But: e.g. in $\mathbb{R}^n$ we have three very different concepts of distance given by the Euclidean, $\ell_1$ and $\ell_\infty$ metrics.
But all give same concept of convergence and continuity.

\begin{definition}[Homeomorphism]
    Let $(X, d)$ and $(Y, e)$ be metric spaces.
    Let $f : X \to Y$.
    We say $f$ is a \vocab{homeomorphism} and that $X, Y$ are \vocab{homeomorphic} if $f$ is a cts bijection with a cts inverse.
\end{definition} 

\begin{remark}
    Homeomorphism is an equivalence `relation' (it satisfies symmetry, transitivity and reflexivity but not an actual relation).
\end{remark} 

\begin{example}
    If $x, y \in \mathbb{R}^n$: $d_\infty(x, y) \leq d_1(x, y) \leq n d_\infty(x, y)$.
    ($d_1, d_\infty \ \ell_1$ and $\ell_\infty$ metrics respectively).
    So identity map $\mathbb{R}^n \to \mathbb{R}^n$ is continuous as map $(\mathbb{R}^n, d_1) \to (\mathbb{R}^n, d_\infty)$ and as a map $(\mathbb{R}^n, d_\infty) \to (\mathbb{R}^n, d_1)$.
    So it's a homeomorphism. \\
    Similarly, $\mathbb{R}^n$ with the Euclidean metric is homeomorphic to both of these spaces.
\end{example} 

\begin{example}
    Same argument would show:
    If $(X, d), (Y, e)$ metric spaces and $f: X \to Y$ is a bijection satisfying 
    \begin{enumerate}
        \item $\exists \; A \ \forall \; x, y \in X \ e(f(x), f(y)) \leq A d(x, y)$
        \item $\exists \; B \ \forall \; x, y \in X \ d(x, y) \leq B e(f(x), f(y))$ then $f, f\inv$ are cts so $X, Y$ homeomorphic.
    \end{enumerate} 
\end{example} 

\begin{example}
    Define $f:(-\frac{\pi}{2}, \frac{\pi}{2}) \to \mathbb{R}$ by $f(x) = \tan x$.
    Then $f$ is a homeomorphism (usual metric in each case).
    But there is no constant $A$ s.t. $\forall \; x, y \in (- \frac{\pi}{2}, \frac{\pi}{2})$ $|\tan x - \tan y| \leq A |x - y|$.
\end{example} 

\begin{proposition}
    Let $(V, b), (W, c), (X, d), (Y, e)$ be metric spaces and $f : X \to V$, $g:Y \to W$ be homeomorphisms.
    \begin{enumerate}
        \item In $X$, $x_n \to x$ iff in $V$ $f(x_n) \to f(x)$;
        \item A function $h: X \to Y$ is cts at $a \in X$ iff $g \circ h \circ f\inv$ is cts at $f(a) \in V$.
    \end{enumerate} 
\end{proposition} 

\begin{proof}
    (i) $x_n \to x \implies f(x_n) \to f(x)$ as $f$ cts; $f(x_n) \to f(x) \implies x_n = f\inv(f(x_n)) \to f\inv (f(x)) = x$ as $f\inv$ cts.

    (ii) $h$ cts $\implies$ $g \circ h \circ f\inv$ cts (composition of cts fcns).
    And $g \circ h \circ f\inv$ cts $\implies h = g\inv \circ (g \circ h \circ f\inv) \circ f$ is cts (similarly).
\end{proof} 

We now have examples of metric spaces that look very different but behave identically w.r.t convergence/ continuity.

\underline{Thought}: Could we dispense with distance altogether?

Another way to think about continuity.

\begin{definition}[Open ball]
    Let $(X, d)$ be a metric space, let $a \in X$ and let $\epsilon > 0$.
    The \vocab{open ball of radius $\epsilon$ about $a$} is the set $B_\epsilon(a) = \{ x \in X : d(x, a) < \epsilon\}$.
\end{definition} 

\begin{remark}
    Suppose $f: X \to Y$, $a \in X$.
    $d$ metric on $X$, $e$ metric on $Y$.
    \begin{align*}
        f \text{ cts at } a &\iff \forall \; \epsilon > 0 \ \exists \; \delta > 0 \ d(x, a) < \delta \implies d(f(x), f(a)) < \epsilon \\
        &\iff \forall \; \epsilon > 0 \ \delta > 0 \ x \in B_\delta(a) \implies f(x) \in B_\epsilon(f(a)) \\
        &\iff \forall \; \epsilon > 0 \ \exists \; \delta > 0 \ f(B_\delta(a)) \subset B_\epsilon(f(a)) \\
        &\iff \forall \; \epsilon > 0 \ \exists \; \delta > 0 \ B_\delta(a) \subset f\inv(B_\epsilon(f(a))).
    \end{align*} 
    So we have redefined continuity in terms of open balls.
    But open balls have radii so still mentioning distance.
\end{remark} 

\begin{definition}[Open, Neighbourhood]
    Let $X$ be a metric space.
    A subset $G \subset X$ is \vocab{open} if $\forall \; x \in G \ \exists \; \epsilon > 0 \ B_\epsilon(x) < G$.
    A subset $N \subset X$ is a \vocab{neighbourhood} (nbd) of a point $a \in X$ if there exists an open set $G \subset X$ s.t. $a \in G \subset N$.
\end{definition} 

\begin{remark} \
    \begin{enumerate}
        \item \color{blue} Intuition: \color{black} A set is open if for each point in the set it contains all points nearby as well.
        A set is a neighbourhood of $a$ if it contains all points near $a$.
        \item The open ball $B_\epsilon(a)$ is open.
        Why?
        If $x \in B_\epsilon(a)$ then $d(x, a) = \delta < \epsilon$, say so by $\Delta$ inequality $B_{\epsilon - \delta}(x) \subset B_\epsilon(a)$.
        \item If $\mathcal{N}$ is an open set and $a \in \mathcal{N}$ then certainly $\mathcal{N}$ is a nbd (neighbourhood) of $a$: $a \in \underbracket{\mathcal{N}}_\text{open} \subset \mathcal{N}$. \\
        However, a nbd of $a$ need not be open.
        E.g. in $\mathbb{R}$ with the usual metric then $[-1, 1]$ is a nbd of $0$: $0 \in \underbracket{(0, 1)}_\text{open} \subset [-1, 1]$.
        And $[-1, 1] \cup \{396\}$ is a nbd of $0$.
        \item $\mathcal{N}$ is a nbd of $a$ iff $\exists \; \epsilon > 0$ s.t. $B_\epsilon(a) \subset N$.
        \begin{proof}
            ($\Longleftarrow$): $a \in \underbracket{B_\epsilon(a)}_\text{open} \subset \mathcal{N}$. \\
            ($\implies$): $a \in \underbracket{G}_\text{open} \subset \mathcal{N}$ and $\exists \; \epsilon > 0$ s.t. $B_\epsilon(a) \subset G$.
        \end{proof} 
        \item A set $G$ is open iff it's a nbd of each of its points.
    \end{enumerate} 
\end{remark} 

\begin{proposition} \label{prp:23}
    Let $(X, d), (Y, e)$ be metric spaces and let $f : X \to Y$.
    \begin{enumerate}
        \item $f$ is cts at $a \in X$ iff whenever $\mathcal{N} \subset Y$ is a nbd of $f(a)$ we have $f\inv(\mathcal{N}) \subset X$ a nbd of a;
        \item $f$ is a cts function iff whenever $G \subset Y$ is open we have $f\inv(G) \subset X$ open.
    \end{enumerate} 
\end{proposition} 

\begin{proof} \
    \begin{enumerate}
        \item ($\implies$): Suppose $f$ cts at $a \in X$.
        Let $\mathcal{N}$ be a nbd of $f(a)$.
        Then $\exists \; \epsilon > 0$ s.t. $B_\epsilon(f(a)) \subset \mathcal{N}$.
        But $f$ cts at $a$ so $\exists \; \delta > 0$ s.t. $B_\delta(a) \subset f\inv (B_\epsilon(f(a))) \subset f\inv (\mathcal{N})$.
        So $f\inv(\mathcal{N})$ is a nbd of $a$.

        ($\Longleftarrow$): Suppose $f\inv(\mathcal{N})$ is a nbd of $a$ for every nbd $\mathcal{N}$ of $f(a)$.
        Let $\epsilon > 0$.
        In particular, $B_\epsilon(f(a))$ is a nbd of $f(a)$ so $f\inv(B_\epsilon(f(a)))$ is a nbd of $a$ so $\exists \; \delta > 0$ s.t. $B_\delta(a) \subset f\inv (B_\epsilon (f(a)))$.
        So $f$ is cts at $a$.

        \item ($\implies$): Suppose $f$ is a cts function.
        Let $G \subset Y$ be open.
        Let $a \in f\inv(G)$.
        Then $f(a) \in G$ and $G$ open so $G$ is a nbd of $f(a)$.
        Moreover, $f$ is cts at $a$ so by (i) we have $f\inv(G)$ a nbd of $a$.
        Hence $\exists \; \delta > 0$ s.t. $B_\delta(a) \subset f\inv(a)$.
        So $f\inv(a)$ is open.

        ($\Longleftarrow$): Suppose $f\inv(G)$ open whenever $G$ is open in $Y$.
        Let $a \in X$.
        Let $\mathcal{N} \subset Y$ be a nbd of $f(a)$.
        Then $\exists \; G \subset Y$ open s.t. $f(a) \in G \subset \mathcal{N}$.
        By assumption, $f\inv(G) \subset X$ open.
        Now $a \in f\inv(G) \subset f\inv(\mathcal{N})$ with $f\inv(G)$ open so $f\inv(\mathcal{N})$ is nbd of $a$.
        So by $(i)$, $f$ is cts at $a$.
        So $f$ is a cts function.
    \end{enumerate} 
\end{proof} 

\begin{remark}
    \begin{enumerate}
        \item This says that we can define continuity entirely in terms of open sets without mentioning the metric.
        \item We saw previously that homeomorphisms preserve convergence and continuity.
        \Cref{prp:23} (ii) say homeomorphisms also preserve open sets: precisely, if $f : X \to Y$ is a homeomorphism then $G \subset X$ is open iff $f(G) \subset Y$ is open.
        (Why? $G = f\inv(f(G))$ with $f$ cts and $f(G) = (f\inv)\inv(G)$ with $f\inv$ cts.)
    \end{enumerate} 
\end{remark} 

What else is preserved by homeomorphisms? \\
Suppose $f: X \to Y$ is a homeomorphism and $X$ is sequentially compact.
Let $(y_n)$ be a sequence in $Y$.
Then $(f\inv(y_n))$ is a sequence in $X$ and so has a convergent subsequence.
$f\inv(y_{n_j}) \to x \in X$, say.
But convergence of sequences is preserved by homeomorphisms.
Hence $(y_{n_j}) = f(f\inv(y_{n_j})) \to f(x) \in Y$.
So $Y$ is sequentially compact.

Thus if $X, Y$ homeomorphic spaces, $X$ sequentially compact $\iff$ $Y$ sequentially compact.

`Sequential compactness is a \underline{topological property}\footnote{This means it is preserved by homeomorphisms}'.
If $X, Y$ homeomorphic and one has the property then so does the other.

What about completeness?
Not so good.

\begin{example}
    We saw $(0, 1)$ and $\mathbb{R}$ with the usual metric in each case are homeomorphic.
    But $\mathbb{R}$ is complete and $(0, 1)$ is not.
    So completeness is not a topological property.
\end{example} 

What went wrong?
Property of being a Cauchy sequence is not preserved by homeomorphisms.

\begin{remark}
    Suppose $(x_n)$ is a sequence in a metric space $X$ and $x \in X$.
    Then
    \begin{align*}
        x_n \to x &\iff \forall \; \epsilon > 0 \ \exists \; N \ \forall \; n \geq N \ d(x_n, x) < \epsilon \\
        &\iff \forall \; \epsilon > 0 \ \exists \; N \ \forall \; n \geq N \ x_n \in B_\epsilon(x) \\
        &\iff \text{for all nbds $\mathcal{N}$ of $x$ $\exists \; N \ \forall \; n \geq N \ x_n \in \mathcal{N}$.}
    \end{align*} 
    This defines convergence solely in terms of nbds.
    Can't do something similar for Cauchy sequences using nbds/ open sets.
\end{remark} 

We have just seen that seq. compactness is a topological property.
We can define seq. compactness just in terms of nbds/ open sets:
Seq. compact is defined in terms of convergence of sequences which can be described using nbds.
But is there a `nicer' way to do this, can we describe just in terms of open sets?

\begin{definition}[Open Cover]
    Let $X$ be a metric space.
    An \vocab{open cover} of $X$ is a collection $\mathcal{C}$ of open subsets of $X$ s.t. $X = \bigcup_{G \in \mathcal{C}} G$.
\end{definition} 

\begin{definition}[Subcover]
    A \vocab{subcover} of $\mathcal{C}$ is an open cover $\mathcal{B}$ of $X$ with $\mathcal{B} \subset \mathcal{C}$.
\end{definition} 

\begin{definition}[Compact]
    We say $X$ is \vocab{compact} if every open cover of $X$ has a finite subcover.
\end{definition} 

\begin{example}[The Heine-Borel Theorem]
    $[0, 1]$ with the usual metric is compact.
\end{example} 

\begin{proof}
    Let $\mathcal{C}$ be an open cover of $[0, 1]$. \\
    Let $A = \{ x \in [0, 1] : \exists \; \mathcal{B} \subset \mathcal{C} \text{ finite with } [0, x] \subset \bigcup_{G \in \mathcal{B}} G \}$.
    We know $\exists \; G \in \mathcal{C}$ with $0 \in G$.
    So $0 \in A$ so $A \neq \emptyset$.
    Clearly $A$ bounded above by $1$.
    So $A$ has supremum, say $\sigma = \sup A$.

    As $G$ open, $\exists \; \epsilon > 0$ s.t. $[0, \epsilon) = B_\epsilon(0) \subset G$.
    So $\frac{\epsilon}{2} \in A$ so $\sigma > 0$.

    Suppose $\sigma < 1$.
    We can find $H \in \mathcal{C}$ with $\sigma \in H$.
    As $\sigma = \sup A$ we can find $x \in A$ with $x \in H$.
    So we have $\mathcal{B} \subset \mathcal{C}$ finite with $[0, x] \subset \bigcup_{G \in \mathcal{B}} G$.
    But $\exists \; \epsilon > 0$ s.t. $(\sigma - \epsilon, \sigma + \epsilon) = B_\epsilon(\sigma) \subset H$.
    So $[0, \sigma + \frac{\epsilon}{2}] \subset \bigcup_{G \in \mathcal{B} \cup \{H\}} G$.
    So $\sigma + \frac{\epsilon}{2} \in A$ \Lightning.

    Hence $\sigma = 1$.
    We can find $K \in \mathcal{C}$ s.t. $1 \in K$.
    As $K$ open, we can find $\epsilon > 0$ s.t. $(1 - \epsilon, 1] = B_\epsilon(1) \subset K$.
    As $1 = \sup A$ we can find $x \in A \cap (1 - \epsilon, 1]$.
    That says we have finite $\mathcal{B} \subset \mathcal{C}$ with $[0, x] \subset \bigcup_{G \in \mathcal{B}} G$.

    Then $\mathcal{B} \cup \{K\}$ is an open cover of $[0, 1]$ and so a subcover of $\mathcal{C}$.
    So $[0, 1]$ is compact.
\end{proof} 

\begin{theorem}
    Let $X$ be a metric space.
    Then TFAE:
    \begin{enumerate}
        \item $X$ is compact;
        \item $X$ is sequentially compact;
        \item $X$ is complete and totally bounded;
        \item $X$ is a subspace of $\mathbb{R}^n$ with the Euclidean metric. $X \subset \mathbb{R}^n$ is closed and bounded.
    \end{enumerate} 
\end{theorem} 

\begin{proof}
    We have already shown (2) $\iff$ (3) ($\iff$ (4) if appropriate) in previous section 2.3. \\
    So only remains to prove (1) $\iff$ (2).

    ($\implies$): Suppose $X$ is not sequentially compact.
    Then there is some sequence $(x_n)$ in $X$ with no convergent subsequence.
    Hence for every point $a \in X$ we can find a nbd of $a$ and hence an open set $G_a$ containing $a$ but containing $(x_n)$ for only finitely many values of $n$. (If not, pick an $a$ for which this is not true; then take $n$ s.t. $x_{n_1} \in B_1(a)$, then $n_2 > n_1$ s.t. $x_{n_2} \in B_{\frac{1}{2}}(a)$, then $x_{n_3} \in B_{\frac{1}{3}}(a)$ with $n_3 > n_2$, \dots, giving $x_{n_j} \to a$ \Lightning).

    Now let $\mathcal{C} = \{ G_a : a \in X\}$.
    This is an open cover of $X$.
    But if $\mathcal{D} \subset \mathcal{C}$ is finite then $\bigcup_{G \in \mathcal{D}} G$ contains $x_n$ for only finitely many $n$, so $\bigcup_{G \in \mathcal{D}} \neq X$.
    So $\mathcal{C}$ has no finite subcover.
    Hence $X$ is not compact.

    ($\Longleftarrow$): Suppose $X$ is sequentially compact. \\
    Let $\mathcal{C}$ be an open cover of $X$.
    \begin{claim}
        $\exists \; \delta > 0 \ \forall \; a \in X \ \exists \; G \in \mathcal{C} \ B_\delta(a) \subset G$.
    \end{claim} 

    \begin{proof}
        Suppose not.
        Then $\forall \; \delta > 0 \ \exists \;a \in X \ \forall \; G \in \mathcal{C} \ B_\delta(a) \not\subset G$.
        Taking $\delta = \frac{1}{n}$ for each $n \in \mathbb{N}$ we obtain a sequence $(x_n)$ in $X$ s.t. for each $n$, $\forall \; G \in \mathcal{C} \ B_\frac{1}{n}(x_n) \not\subset G$. \\
        By sequential compactness, we can find a convergent subsequence $x_{n_j} \to a \in X$.
        Pick $G \in \mathcal{C}$ s.t. $a \in G$.
        As $G$ open, we can pick $\epsilon > 0$ s.t. $B_\epsilon(a) \subset G$.
        Pick $j$ sufficiently large s.t. $x_{n_j} \in B_{\frac{\epsilon}{2}}(a)$ and also $\frac{1}{n_j} < \frac{\epsilon}{2}$.
        Then $B_{\frac{1}{n_j}}(x_{n_j}) \subset B_\epsilon(a) \subset G$.
    \end{proof} 

    Now take $\delta$ as in the claim.
    As $X$ is sequentially compact, it is totally bounded so we can find a finite set $A \subset X$ s.t. $\forall \; x \in X \ \exists \; a \in A \ d(x, a) < \delta$.
    That is $\forall \; x \in X \ \exists \; a \in A \ x \in B_\delta(a)$.
    That is, $X = \bigcup_{a \in A} B_\delta(a)$.
    By choice of $\delta$, for each $a \in A$ we can pick $G_a \in \mathcal{C}$ s.t. $B_\delta(a) \subset G_a$.
    So $\{G_a : a \in A\}$ is a finite subcover.
    So $X$ is compact.
\end{proof} 

Finally, two important properties of open sets.
First: relationship between open/ closed.
\begin{proposition} \label{prp:25}
    Let $X$ be a metric space and $G \subset X$.
    Then $G$ is open iff $F = X \setminus G$ is closed.
\end{proposition} 

\begin{proof}
    ($\implies$) Suppose $F$ not closed.
    Then there is a sequence $(x_n)$ in $F$ with $x_n \to x \notin F$ so $x \in G$.
    Suppose $\mathcal{N}$ is a nbd of $x$.
    Then $\exists \; N$ s.t. $\forall \; n \geq N \ x_n \in \mathcal{N}$.
    But $\forall \; n \ x_n \notin G$.
    So $\mathcal{N} \neq G$.
    So $G$ is not a nbd of $x \in G$.
    So $G$ is not open.

    ($\Longleftarrow$): Suppose $G$ is not open.
    Then there is some $x \in G$ s.t. $\forall \; \epsilon > 0 \ B_\epsilon(x) \not\subset G$.
    That is $B_\epsilon(x) \cap F \neq \emptyset$.
    So for $n \in \mathbb{N}$ we can pick $x_n \in B_{\frac{1}{n}}(x) \cap F$.
    Then $(x_n)$ is a sequence in $F$ with $x_n \to x \in G$.
    So $F$ is not closed.
\end{proof} 

Secondly: If $X$ is a metric space, can we say something about the structure of the collection of all open subsets of $X$?

\begin{proposition} \label{prp:26}
    Let $X$ be a metric space and let $\tau = \{ G \subset X : G \text{ open}\}$.
    Then \begin{enumerate}
        \item $\emptyset \in \tau$ and $X \in \tau$;
        \item if $\sigma \subset \tau$ then $\bigcup_{G \in \sigma} G \in \tau$, `any union of open sets is open';
        \item If $G_1, G_2, \dots, G_n \in \tau$ then $\bigcap_{i = 1}^n G_i \in \tau$, `a finite intersection of open sets is open'.
    \end{enumerate} 
\end{proposition} 

\begin{remark}
    We do need finiteness condition in (3).
    E.g. $\forall \; n \in \mathcal{N}$, $(-\frac{1}{n}, \frac{1}{n})$ is open in $\mathbb{R}$ with the usual metric.
    But $\bigcap_{n = 1}^\infty (-\frac{1}{n}, \frac{1}{n}) = \{0\}$ which is not open.
\end{remark} 

\begin{proof}
    \begin{enumerate}
        \item Obvious
        \item Suppose $\sigma \subset \tau$.
        Let $H = \bigcup_{G \in \sigma} G$.
        Suppose $a \in H$.
        Then $a \in G$ for some $G \in \sigma$.
        So $G$ is a nbd of $a$ (as $G$ open).
        So $H$ is a nbd of $a$ (as $G \subset H$).
        Hence $H$ is open, i.e. $H \in \tau$.
        \item Suppose $G_1, \dots, G_n \in \tau$ and let $J = \bigcap_{i = 1}^n G_i$.
        Suppose $a \in J$.
        For each $i$, $a \in G_i$ and $G_i$ open so $\exists \; \delta_i \geq 0$ s.t. $B_{\delta_i}(a) \subset G_i$.
        Let $\delta = \min \{\delta_1, \dots, \delta_n\}$\footnote{This is where we need finiteness}.
        Then $\delta > 0$ and $B_\delta(a) = \bigcap_{i = 1}^n B_{\delta_i}(a) \subset \bigcap_{i = 1}^n G_i = J$.
        So $J$ is open, i.e. $J \in \tau$.
    \end{enumerate} 
\end{proof} 