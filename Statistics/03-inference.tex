\section{Inference}

\subsection{Confidence intervals}
\begin{definition}
	A $100 \gamma$\% \textit{confidence interval} for a parameter $\theta$ is a random interval $(A(X), B(X))$ such that $\prob{A(X) \leq \theta \leq B(X)} = \gamma$ for all $\theta \in \Theta$.
	Note that the parameter $\theta$ is assumed to be fixed for the event $\qty{A(X) \leq \theta \leq B(X)}$, and the confidence interval holds uniformly over $\theta$.
\end{definition}
\begin{remark}
	Suppose that an experiment is repeated many times.
	On average, $100 \gamma$\% of the time, the random interval $(A(X), B(X))$ will contain the true parameter $\theta$.
	This is the \textit{frequentist} interpretation of the confidence interval.

	A misleading interpretation is as follows.
	Given that a single value of $X$ is observed, there is a probability $\gamma$ that $\theta \in (A(x), B(x))$.
	This is wrong, as will be demonstrated later.
\end{remark}
\begin{example}
	Let $X_1, \dots, X_n$ be i.i.d.\ normal random variables with unit variance.
	We will find the 95\% confidence interval for $\mu = \theta$.
	We have
	\begin{align*}
		\overline X = \frac{1}{n} \sum_{i=1}^n X_i \sim N\qty(\theta, \frac{1}{n});\quad Z = \sqrt{n}\qty(\overline X - \theta) \sim N(0,1)
	\end{align*}
	Let $a, b$ be numbers such that $\Phi(b) - \Phi(a) = 0.95$.
	Then
	\begin{align*}
		\prob{a \leq \sqrt{n} \qty(\overline X - \theta) \leq b} = 0.95 \implies \prob{\overline X - \frac{b}{\sqrt{n}} \leq \theta \leq \overline X - \frac{a}{\sqrt{n}}} = 0.95
	\end{align*}
	Hence, $\qty(\overline X - \frac{b}{\sqrt{n}}, \overline X - \frac{a}{\sqrt{n}})$ is a 95\% confidence interval for $\theta$.
	Typically, we wish to centre the interval around some estimator $\hat\theta$ such that its range is minimised for a given $\gamma$.
	In this case, we want to set $-a = b = z_{0.025} \approx 1.96$, where $z_\alpha = \Phi^{-1}(1-\alpha)$.
	Hence, the confidence interval is $\qty(\overline X \pm \frac{1.96}{\sqrt{n}})$.
\end{example}
\begin{remark}
	In general, to find a confidence interval:
	\begin{enumerate}
		\item Find a quantity $R(X,\theta)$ where the distribution $\mathbb P_\theta$ does not depend on $\theta$.
		      This is known as a \textit{pivot}.
		      In the example above, $R(X,\theta) = \sqrt{n}\qty(\overline X - \theta)$.
		\item Consider $\prob{c_1 \leq R(X,\theta) \leq c_2} = \gamma$.
		      Given some desired level of confidence $\gamma$, find $c_1$ and $c_2$ using the distribution function of the pivot.
		\item Rearrange such that $\prob{A(X) \leq \theta \leq B(X)} = \gamma$, then $(A(X), B(X))$ is the confidence interval as required.
	\end{enumerate}
\end{remark}
\begin{proposition}
	Let $T$ be a monotonically increasing function, and let $(A(X), B(X))$ be a $100 \gamma$\% confidence interval for $\theta$.
	Then $(T(A(X)), T(B(X)))$ is a $100 \gamma$\% confidence interval for $T(\theta)$.
\end{proposition}
\begin{remark}
	If $\theta$ is a vector, we can consider confidence sets instead of confidence intervals.
	A confidence set is a set $A(X)$ such that $\prob{\theta \in A(X)} = \gamma$.
\end{remark}
\begin{example}
	Let $X_1, \dots, X_n$ be i.i.d.\ normal random variables with zero mean and unknown variance $\sigma^2$.
	We will find a 95\% confidence interval for $\sigma^2$.
	Note that $\frac{X_1}{\sigma} \sim N(0,1)$ is a valid pivot, but it considers only one data point.
	We will instead consider
	\begin{align*}
		R(X, \sigma^2) = \sum_i \frac{X_i^2}{\sigma^2} \sim \chi^2_n
	\end{align*}
	Now, we can define $c_1 = F_{\chi^2_n}^{-1}(0.025)$ and $c_2 = F_{\chi^2_n}^{-1}(0.975)$, giving
	\begin{align*}
		\prob{c_1 \leq \sum_{i=1}^n \frac{X_i^2}{\sigma^2} \leq c^2} = 0.95
	\end{align*}
	Rearranging, we have
	\begin{align*}
		\prob{\frac{\sum X_i^2}{c_2} \leq \sigma^2 \leq \frac{\sum X_i^2}{c_1}} = 0.95
	\end{align*}
	Hence, the interval $\sum_{i=1}^n X_i^2 \qty(\frac{1}{c_2}, \frac{1}{c_1})$ is a 95\% confidence interval for $\sigma^2$.
\end{example}
\begin{example}
	Let $X_1, \dots, X_n$ be i.i.d.\ Bernoulli random variables with parameter $p$.
	Suppose $n$ is large.
	We will find an approximate 95\% confidence interval for $p$.
	The maximum likelihood estimator is
	\begin{align*}
		\hat p = \overline X = \frac{1}{n} \sum_{i=1}^n X_i
	\end{align*}
	By the central limit theorem, $\hat p$ is asymptotically distributed according to $N\qty(p, \frac{p(1-p)}{n})$.
	Hence,
	\begin{align*}
		\sqrt{n}\frac{\hat p - p}{\sqrt{p(1-p)}}
	\end{align*}
	has approximately a standard normal distribution.
	We have
	\begin{align*}
		\prob{-z_{0.025} \leq \sqrt{n}\frac{\hat p - p}{\sqrt{p(1-p)}} \leq z_{0.025}} \approx 0.95
	\end{align*}
	Instead of directly rearranging the inequalities, we will make an approximation for the denominator of the central term, letting $\sqrt{p(1-p)} \mapsto \sqrt{\hat p\qty(1-\hat p)}$.
	When $n$ is large, this approximation becomes more accurate.
	\begin{align*}
		\prob{-z_{0.025} \leq \sqrt{n}\frac{\hat p - p}{\sqrt{\hat p\qty(1-\hat p)}} \leq z_{0.025}} \approx 0.95
	\end{align*}
	This is much easier to rearrange, leading to
	\begin{align*}
		\prob{\hat p - z_{0.025}\frac{\sqrt{\hat p\qty(1-\hat p)}}{\sqrt{n}} \leq p \leq \hat p + z_{0.025}\frac{\sqrt{\hat p\qty(1-\hat p)}}{\sqrt{n}}} \approx 0.95
	\end{align*}
	This gives the approximate 95\% confidence interval as required.
\end{example}
\begin{remark}
	Note that the size of the confidence interval is maximised at $p = \frac{1}{2}$, with a length of $2z_{0.025} \frac{1}{2\sqrt{n}} \approx \frac{1}{\sqrt{n}}$.
	This is a \textit{conservative} 95\% confidence interval; it may be wider than necessary but holds for all values of $\theta$.
\end{remark}

\subsection{Interpreting the confidence interval}
\begin{example}
	Let $X_1, X_2$ be i.i.d.\ uniform random variables in $\qty(\theta - \frac{1}{2}, \theta + \frac{1}{2})$.
	We wish to estimate the value of $\theta$ with a 50\% confidence interval.
	Observe that
	\begin{align*}
		\prob{\theta \in (\min X_i, \max X_i)} = \prob{X_1 \leq \theta \leq X_2} + \prob{X_2 \leq \theta \leq X_1} = \frac{1}{2}
	\end{align*}
	Hence, $(\min X_1, \max X_i)$ is a 50\% confidence interval for $\theta$.
	The frequentist interpretation is exactly correct; 50\% of the time, $\theta$ will lie between $X_1$ and $X_2$.
	However, suppose that $\abs{X_1 - X_2} > \frac{1}{2}$.
	Then we know that $\theta \in (\min X_i, \max X_i)$.
	Suppose $X_1 = 0.1, X_2 = 0.9$, then it is not sensible to say that there is a 50\% chance that $\theta \in [0.1, 0.9]$.
\end{example}
