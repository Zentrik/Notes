\section{Elementary Properties}

\subsection{Communicating classes}
\begin{definition}[Communication]
	Let $X$ be a Markov chain with transition matrix $P$ and values in $I$.
	For $x, y \in I$, we say that $x$ \textit{leads to} $y$, written $x \to y$, if
	\begin{align*}
		\psubx{\exists n \geq 0, X_n = y} > 0
	\end{align*}
	We say that $x$ \textit{communicates with} $y$ and write $x \leftrightarrow y$ if $x \to y$ and $y \to x$.
\end{definition}

\begin{theorem}
	The following are equivalent:
	\begin{enumerate}
		\item $x \to y$
		\item There exists a sequence of states $x = x_0, x_1, \dots, x_k = y$ such that
		      \begin{align*}
			      P(x_0, x_1)P(x_1,x_2)\dots P(x_{k-1},x_k) > 0
		      \end{align*}
		\item There exists $n \geq 0$ such that $p_{xy}(n) > 0$.
	\end{enumerate}
\end{theorem}
\begin{proof}
	First, we show (i) and (iii) are equivalent.
	If $x \to y$, then $\psubx{\exists n \geq 0, X_n = y} > 0$.
	Then if $\psubx{\exists n \geq 0, X_n = y} > 0$ we must have some $n \geq 0$ such that $\psubx{X_n = y} = p_{xy}(n) > 0$.
	Note that we can write (i) as $\psubx{\bigcup_{n=0}^\infty X_n = y} > 0$.
	If there exists $n \geq 0$ such that $p_{xy}(n) > 0$, then certainly the probability of the union is also positive.

	Now we show (ii) and (iii) are equivalent.
	We can write
	\begin{align*}
		p_{xy}(n) = \sum_{x_1, \dots, x_{n-1}} P(x, x_1) \dots P(x_{n-1}, y)
	\end{align*}
	which leads directly to the equivalence of (ii) with (iii).
\end{proof}
\begin{corollary}
	Communication. $\leftrightarrow$, is an equivalence relation on $I$.
\end{corollary}
\begin{proof}
	Reflexivity: $x \leftrightarrow x$ since $p_{xx}(0) = 1$. \\
	Transitivity: If $x \to y$ and $y \to z$ then by (ii) above, $x \to z$. \\
	Symmetric by definition.
\end{proof}
\begin{definition}[Communicating Classes]
	The equivalence classes induced on $I$ by the communication equivalence relation are called \vocab{communicating classes}.
\end{definition}

\begin{definition}[Closed Communicating Class]
	A communicating class $C$ is \vocab{closed} if $x \in C, x \to y \implies y \in C$.
\end{definition} 

\begin{definition}[Irreducibility]
	A transition matrix $P$ is called \vocab{irreducible} if it has a single communicating class.
	In other words, $\forall x, y \in I, x \leftrightarrow y$.
\end{definition}

\begin{definition}[Absorption]
	A state $x$ is called \vocab{absorbing} if $\{ x \}$ is a closed (communicating) class.
	Equivalently if the markov chain started from $x$ it stays at $x$ forever.
\end{definition}

\subsection{Hitting times}
\begin{definition}[Hitting Time]
	For $A \subseteq I$, we define the \textit{hitting time} of $A$ to be a random variable $T_A \colon \Omega \to \qty{0,1,2\dots} \cup \{ \infty \}$, defined by
	\begin{align*}
		T_A(\omega) = \inf \qty{n \geq 0 \colon X_n(\omega) \in A}
	\end{align*}
	with the convention that $\inf \varnothing = \infty$.
\end{definition}

\begin{definition}[Hitting Probability]
	The \textit{hitting probability} of $A$ starting at $i \in I$ is $h^A \colon I \to [0,1]$, defined by
	\begin{align*}
		h^A(i) = h_i^A = \psub{i}{T_A < \infty},\ i \in I
	\end{align*}
\end{definition} 

\begin{definition}[Mean Hitting Time]
	The \textit{mean hitting time} of $A$ starting at $i \in I$ is $k^A \colon I \to [0,\infty]$, defined by
	\begin{align*}
		k_i^A = \esub{i}{T_A} = \sum_{n=0}^\infty n \psub{i}{T_A = n} + \underbrace{\infty \psub{i}{T_A = \infty}}_{0 \cdot \infty = 0}
	\end{align*}
\end{definition} 

\begin{example}
	Consider
	\begin{align*}
		P = \begin{pmatrix}
			1   & 0   & 0   & 0   \\
			1/2 & 0   & 1/2 & 0   \\
			0   & 1/2 & 0   & 1/2 \\
			0   & 0   & 0   & 1
		\end{pmatrix}
	\end{align*}
	Consider $A = \qty{4}$.
	\begin{align*}
		h_1^A = 0
	\end{align*}
	\begin{align*}
		h_2^A = \psub{2}{T_A < \infty} = \frac{1}{2} h_1^A + \frac{1}{2} h_3^A
	\end{align*}
	\begin{align*}
		h_3^A = \frac{1}{2} \cdot 1 + \frac{1}{2} h_2^A
	\end{align*}
	Hence $h_2^A = \frac{1}{3}$.

	Now, consider $B = \qty{1,4}$.
	$k_2^B = \mathbb{E}[T_B]$
	\begin{align*}
		k_1^B = k_4^B = 0
	\end{align*}
	\begin{align*}
		k_2^B = 1 + \frac{1}{2} k_1^B + \frac{1}{2} k_3^B
	\end{align*}
	\begin{align*}
		k_3^B = 1 + \frac{1}{2} k_4^B + \frac{1}{2} k_2^B
	\end{align*}
	Hence $k_2^B = 2$.
\end{example}
\begin{theorem}
	Let $A \subset I$.
	Then the vector $(h_i^A)_{i \in I}$ is the minimal non-negative solution to the system
	\begin{align*}
		x_i = \begin{cases}
			1 & i \in A     \\
			\sum_j P(i,j) x_j & i \not\in A\end{cases}
	\end{align*}
	Minimality here means that if $(x_i)_{i \in I}$ is another non-negative solution, then $\forall i, h_i^A \leq x_i$.
\end{theorem}
\begin{note}
	The vector $h_i^A = 1$ always satisfies the equation, since $P$ is stochastic, but this solution is typically not minimal.
\end{note}
\begin{proof}
	First, we will show that $(h_i^A)_{i \in I}$ solves the system of equations.

	Certainly if $i \in A$ then $h_i^A = 1$.
	Suppose $i \not\in A$.
	Consider the event $\qty{T_A < \infty}$.
	We can write this event as a disjoint union of the following events:
	\begin{align*}
		\qty{T_A < \infty} &= \bigcup_{n = 0}^\infty \qty{T_A = n} = \bigcup_{n=0}^\infty \qty{X_0 \not\in A, \dots, X_{n-1} \not\in A, X_n \in A}
	\intertext{By countable additivity,}
		\psub{i}{T_A < \infty} & = \underbrace{\psub{i}{X_0 \in A}}_{=0} + \sum_{n=1}^\infty \psub{i}{X_0 \not\in A, \dots, X_{n-1} \not\in A, X_n \in A}   \\
		&= \mathbb{P}(X_1 \in A) + \sum_{n=2}^{\infty} \mathbb{P}_i(X_1 \not\in A, \dots, X_{n-1} \not\in A, X_n \in A) \\
		\mathbb{P}_i(X_1 \notin A, \dots, X_{n-1} \notin A, X_n \in A) &= \sum_{j \notin A} \mathbb{P}_i(X_1 = j, X_2 \notin A, \dots, X_{n-1} \in A, X_n \in A) \\
		&= \sum_{j \notin A} \mathbb{P}_i(X_2 \notin A, \dots, X_{n-1} \notin A, X_n \in A \mid X_0 = i, X_1 = j) P(i, j) \\
		&= \sum_{j \notin A} P(i, j) \mathbb{P}_j(X_1 \notin A, \dots, X_{n - 2} \notin A, X_{n - 1} \in A) \\
		h_i^A &= \mathbb{P}_i(X_1 \in A) + \sum_{n=1}^{\infty} \sum_{j \notin A} P(i, j) \mathbb{P}_j(X_1 \notin A, \dots, X_n \in A) \\
		&= \sum_{j \in A} h_j^A + \sum_{j \notin A} P(i, j) h_j^A \\
		&= \sum_j P(i, j) h_j^A
	\end{align*}
	So $(h_i^A)_{i \in I}$ satisfies the equation.

	Now we must show minimality.
	If $(x_i)$ is another non-negative solution, we must show that $h_i^A \leq x_i \ \forall \; i$.
	We have for $i \notin A$
	\begin{align*}
		x_i = \sum_j P(i,j) x_j = \sum_{j \in A} P(i,j) + \sum_{j \not\in A} P(i,j) x_j
	\end{align*}
	Substituting again,
	\begin{align*}
		x_i &= \sum_{j \in A} P(i,j) x_j + \sum_{j \not\in A} P(i,j) \qty( \sum_{k \in A} P(j,k) + \sum_{k \not\in A} P(j,k) x_k ) \\
		x_i &= \mathbb{P}_i(X_1 \in A) + \mathbb{P}(X_1 \notin A, X_2 \in A) + \sum_{j \notin A} \sum_{k \notin A} P(i, j) P(j, k) x_k \\
		x_i &\geq \mathbb{P}_i(X_1 \in A) + \mathbb{P}_i(X_1 \notin A, X_2 \in A) + \dots + \mathbb{P}_i(X_1 \notin A, \dots, X_{n-1} \notin A, X_n \in A) \text{ as } x_k \geq 0. \\
		x_i &\geq \mathbb{P}_i(T_a \leq n) \ \forall \; n \in \mathbb{N}
	\end{align*}
	% Then
	% \begin{align*}
	% 	x_i & = \sum_{j_1 \in A} P(i,j_1) + \sum_{j_1 \not\in A} \sum_{j_2 \in A} P(i,j_1)P(j_1,j_2) + \cdots \\
	% 	    & + \sum_{j_1 \not\in A, \dots, j_{n-1} \not\in A, j_n \in A} P(i,j_1)\dots P(j_{n-1},j_n)        \\
	% 	    & + \sum_{j_1 \not\in A \dots, j_n \not\in A} P(i,j_1)\dots P(j_{n-1},j_n) x_{j_n}
	% \end{align*}
	% The last term is non-negative since $x$ is non-negative.
	% So
	% \begin{align*}
	% 	x_i \geq \psub{i}{T_A = 1} + \psub{i}{T_A = 2} + \dots + \psub{i}{T_A = n} \geq \psub{i}{T_A \leq n},\ \forall n \in \mathbb N
	% \end{align*}
	Now, note $\qty{T_A \leq n}$ are a set of increasing functions of $n$, so by continuity of the probability measure, the probability increases to that of the union, $\qty{T_A < \infty} = h_i^A$.
\end{proof}
\begin{example}
	Consider the Markov chain previously explored:
	\begin{align*}
		P = \begin{pmatrix}
			1   & 0   & 0   & 0   \\
			1/2 & 0   & 1/2 & 0   \\
			0   & 1/2 & 0   & 1/2 \\
			0   & 0   & 0   & 1
		\end{pmatrix}
	\end{align*}
	Let $A = \qty{4}$.
	Then $h_1^A = 0$ since there is no route from 1 to 4.
	From the theorem above, the system of linear equations is
	\begin{align*}
		h_2 = \frac{1}{2} h_1 + \frac{1}{2} h_3
	\end{align*}
	\begin{align*}
		h_3 = \frac{1}{2} h_4 + \frac{1}{2} h_2
	\end{align*}
	\begin{align*}
		h_4 = 1
	\end{align*}
	Hence,
	\begin{align*}
		h_2 = \frac{2}{3} h_1 + \frac{1}{3}
	\end{align*}
	\begin{align*}
		h_3 = \frac{1}{3} h_1 + \frac{2}{3}
	\end{align*}
	So the minimal solution arises at $h_1 = 0$.
\end{example}

\begin{example}[Simple random walk on $\mathbb{Z}_+$]
	Consider $I = \mathbb{Z}_+$, and
	\begin{align*}
		P(i, i+1) = p \in (0,1);\quad P(i, i-1) = 1-p = q
	\end{align*} with $\mathbb{P}(0, 1) = 1$.
	Then $h_i = \psub{i}{T_0 < \infty}$ hence $h_0 = 1$.
	The linear equations are
	\begin{align*}
		h_i = p h_{i+1} + q h_{i-1}
	\end{align*}
	\begin{align*}
		p(h_{i+1} - h_i) = q(h_i - h_{i-1})
	\end{align*}
	Let $u_i = h_i - h_{i-1}$.
	Then assuming $p \neq q$,
	\begin{align*}
		\frac{q}{p} u_i = \dots = \qty(\frac{q}{p})^i u_1
	\end{align*}
	Hence
	\begin{align*}
		h_i = \sum_{j=1}^i (h_j - h_{j-1}) + 1 = 1 - (1-h_1) \sum_{j=1}^i \qty(\frac{q}{p})^j
	\end{align*}
	The general solution is therefore
	\begin{align*}
		h_i = a + b \qty(\frac{q}{p})^i
	\end{align*} with $h_0 = a + b = 1$.
	If $q > p$, then minimality of $h_i$ implies $b = 0$, $a = 1$.
	Hence,
	\begin{align*}
		h_i = 1
	\end{align*}
	Otherwise, if $p > q$, minimality of $h_i$ implies $a = 0$, $b = 1$.
	Hence,
	\begin{align*}
		h_i = \qty(\frac{q}{p})^i
	\end{align*}
	If $p = q = \frac{1}{2}$, then
	\begin{align*}
		h_i = \frac{1}{2} h_{i+1} + \frac{1}{2} h_{i-1}
	\end{align*}
	Hence, $h_i = a + bi$.
	$h_0 = a = 1$ and minimality implies $b = 0$.
	\begin{align*}
		h_i = 1.
	\end{align*}
\end{example}

\subsection{Birth and death chain}
Consider a Markov chain with
\begin{align*}
	P(0, 0) = 1;\quad P(i,i+1) = p_i;\quad P(i,i-1) = q_i;\quad \forall i,\ p_i, q_i \in (0, 1), \ p_i + q_i = 1
\end{align*}
Now, consider $h_i = \psub{i}{T_0 < \infty}$.
$h_0 = 1$, and $h_i = p_i h_{i+1} + q_i h_{i-1}$.
\begin{align*}
	p_i (h_{i+1} - h_i) = q_i (h_i - h_{i-1})
\end{align*}
Let $u_i = h_i - h_{i-1}$ ($u_1 = h_1 - 1$) to give
\begin{align*}
	u_{i+1} = \frac{q_i}{p_i} u_i = \underbrace{\prod_{j=1}^i \frac{q_i}{p_i}}_{\gamma_i} u_i
\end{align*}
Then
\begin{align*}
	h_i &= \sum_{j=1}^{i} (h_j - h_{j - 1}) + 1 \\
	&= \sum_{j=1}^{i} u_j \\
	&= 1 + u_1 + \sum_{j=1}^{i-1} \gamma_j u_1 \\  
	h_i &= 1 + (h_1 - 1) \qty( \gamma_0 + \gamma_1 + \dots + \gamma_{i-1}) \\
	&= 1 - (1 - h_1) \qty( \gamma_0 + \gamma_1 + \dots + \gamma_{i-1})
\end{align*}
where we let $\gamma_0 = 1$.
Since $h_i$ is a non-negative solution,
\begin{align*}
	h_i \geq 0 \implies 1 - h_1 \leq \frac{1}{\sum_{j=0}^{i-1} \gamma_j} \leq \frac{1}{\sum_{j=0}^{\infty} \gamma_j}
\end{align*}
By minimality, we must have exactly this bound.
If $\sum_{j=0}^\infty \gamma_j = \infty$ then $1 - h_1 = 0 \implies h_i = 1$ for all $i$.
If $\sum_{j=0}^\infty \gamma_j < \infty$ then
\begin{align*}
	h_i = \frac{\sum_{j=i}^\infty \gamma_j}{\sum_{j=0}^\infty \gamma_j}.
\end{align*}

\subsection{Mean hitting times}
Recall that
\begin{align*}
	k_i^A = \esub{i}{T_A} = \sum_n n \psub{i}{T_A = n} + \infty \psub{i}{T_A = \infty}
\end{align*}
\begin{theorem}
	The vector $(k_i^A)_{i \in I}$ is the minimal non-negative solution to the system of equations
	\begin{align*}
		x_i = \begin{cases}
			0 & \text{if } i \in A \\
			1 + \sum_{j \not\in A} P(i,j) x_j & \text{if } i \not\in A
		\end{cases}
	\end{align*}
\end{theorem}
\begin{proof}
	Suppose $i \in A$.
	Then $k_i = 0$.
	Now suppose $i \not\in A$.
	Further, we may assume that $\psub{i}{T_A = \infty} = 0$, since if that probability is positive then the claim is trivial.
	Indeed, if $\psub{i}{T_A = \infty} > 0$, then there must exist $j$ such that $P(i,j) > 0$ and $\psub{j}{T_A = \infty} > 0$ since
	\begin{align*}
		\psub{i}{T_A < \infty} = \sum_j P(i,j) h_j^A \implies 1 - \psub{i}{T_A = \infty} = \sum_j P(i,j) \qty(1 - \psub{j}{T_A = \infty})
	\end{align*}
	Because $P$ is stochastic,
	\begin{align*}
		\psub{i}{T_A = \infty} = \sum_j P(i,j) \psub{j}{T_A = \infty}
	\end{align*}
	so since the left hand side is positive, there must exist $j$ with $P(i,j) > 0$ and $\psub{j}{T_A = \infty > 0}$.
	For this $j$, we also have $k_j^A = \infty$.
	Now we only need to compute $\sum_n n\psub{i}{T_A = n}$.
	\begin{align*}
		\psub{i}{T_A = n} = \psub{i}{X_0 \not\in A, \dots, X_{n-1} \not\in A, X_n \in A}
	\end{align*}
	Then, using the same method as the previous theorem,
	\begin{align*}
		k_i^A = \sum_n n \psub{i}{T_A = n} = 1 + \sum_{j \not\in A} P(i,j) k_j^A
	\end{align*}
	It now suffices to prove minimality.
	Suppose $(x_i)$ is another solution to this system of equations.
	We need to show that $x_i \geq k_i^A$ for all $i$.
	Suppose $i \not\in A$.
	Then
	\begin{align*}
		x_i = 1 + \sum_{j \not\in A} P(i,j) x_j = 1 + \sum_{j \not\in A} P(i,j) \qty(1 + \sum_{k \not\in A} P(j,k) x_k)
	\end{align*}
	Expanding inductively,
	\begin{align*}
		x_i & = 1 + \sum_{j_1 \not\in A} P(i,j_1) + \sum_{j_1 \not\in A, j_2 \not\in A} P(i,j_1)P(j_1,j_2) + \cdots                                                               \\
		    & + \sum_{j_1 \not\in A, \dots, j_n \not\in A} P(i,j_1) \dots P(j_{n-1}, j_n) + \sum_{j_1 \not\in A, \dots, j_{n+1} \not\in A} P(i,j) \dots P(j_n,j_{n+1})x_{j_{n+1}}
	\end{align*}
	Since $x$ is non-negative, we can remove the last term and reach an inequality.
	\begin{align*}
		x_i \geq 1 + \sum_{j_1 \not\in A} P(i,j_1) + \sum_{j_1 \not\in A, j_2 \not\in A} P(i,j_1)P(j_1,j_2) + \dots + \sum_{j_1 \not\in A, \dots, j_n \not\in A} P(i,j_1) \dots P(j_{n-1}, j_n)
	\end{align*}
	Hence
	\begin{align*}
		x_i & \geq 1 + \psub{i}{T_A > 1} + \psub{i}{T_A > 2} + \dots + \psub{i}{T_A > n}              \\
		    & = \psub{i}{T_A > 0} + \psub{i}{T_A > 1} + \psub{i}{T_A > 2} + \dots + \psub{i}{T_A > n} \\
		    & = \sum_{k = 0}^n \psub{i}{T_A > k}
	\end{align*}
	for all $n$.
	Hence, the limit of this sum is
	\begin{align*}
		x_i \geq \sum_{k=0}^\infty \psub{i}{T_A > k} = \esub{i}{T_A}
	\end{align*}
	which gives minimality as required.
\end{proof}

\subsection{Strong Markov property}
The simple Markov property shows that, if $X_m = i$,
\begin{align*}
	X_{m + n} \sim \Markov{\delta_i, P}
\end{align*}
and this is independent of $X_0, \dots, X_m$.
The strong Markov property will show that the same property holds when we replace $m$ with a finite random `time' variable.
It is not the case that \textit{any} random variable will work; indeed, an $m$ very dependent on the Markov chain itself might not satisfy this property.
\begin{definition}[Stopping Time]
	A random time $T \colon \Omega \to \qty{0, 1, \dots} \cup \qty{\infty}$ is called a \vocab{stopping time} if, for all $n \in \mathbb N$, $\qty{ T = n }$ depends only on $X_0, \dots, X_n$.
\end{definition}
\begin{example}
	The hitting time $T_A = \inf \qty{ n \geq 0 \colon X_n \in A}$ is a stopping time.
	This is because we can write
	\begin{align*}
		\qty{T_A = n} = \qty{X_0 \not\in A, \dots, X_{n-1} \not\in A, X_n \in A}
	\end{align*}
	So first hitting times are always stopping times.
\end{example}

\begin{example}
	The time $L_A = \sup \qty{n \geq 0 \colon X_n \in A}$ is not a stopping time.
	This is because we need to know information about the future behaviour of $X_n$ in order to guarantee that we are at the supremum of such events.
\end{example}
\begin{theorem}[Strong Markov Property]
	Let $X \sim \Markov{\lambda, P}$ and $T$ be a stopping time.
	Conditional on $T < \infty$ and $X_T = i$,
	\begin{align*}
		\qty(X_{n + T})_{n \geq 0} \sim \Markov{\delta_i, P}
	\end{align*}
	and this distribution is independent of $X_0, \dots, X_T$.
\end{theorem}
\begin{proof}
	We need to show that, for all $x_0, \dots, x_n \in I$ and for all vectors $w$ of any length with elements in $I$,
	\begin{align*}
		 & \prob{X_T = x_0, \dots, X_{T+n} = x_n, (X_0, \dots, X_T) = w \mid T < \infty, X_T = i}                    \\
		 & = \delta_{i x_0} P(x_0,x_1) \dots P(x_{n-1}, x_n) \prob{(X_0, \dots, X_T) = w \colon T < \infty, X_T = i}
	\end{align*}
	Suppose that $w$ is of the form $w = (w_0, \dots, w_k)$.
	Then,
	\begin{align*}
		 & \prob{X_T = X_0, \dots, X_{T+n} = x_n, (X_0, \dots, X_T) = w \mid T < \infty, X_T = i} \\
		 &= \prob{X_k = X_0, \dots, X_{k+n} = x_n, (X_0, \dots, X_k) = w \mid T < \infty, X_T = i} \\
		 & = \frac{\prob{X_k = x_0, \dots, X_{k+n} = x_n, (X_0, \dots, X_k)=w, T=k,X_k=i}}{\prob{T < \infty, X_T = i}}
	\end{align*}
	
	Now, since $\qty{T=k}$ depends \underline{only} on $X_0, \dots, X_k$ by the simple Markov property
	\begin{align*}
		 & \prob{X_k = x_0, \dots, X_{k+n} = x_n \mid (X_0, \dots, X_k) = w, T = k, X_k = i} \\
		 & = \prob{X_k = x_0, \dots, X_{k+n} = x_n \mid X_k = i} = \delta_{i x_0} P(x_0, x_1) \dots P(x_{n-1}, x_n)
	\end{align*}
	\begin{align*}
		\frac{\mathbb{P}((X_0, \dots, X_k) = w, T = k, X_k = i)}{\prob{T < \infty, X_T = i}} &= \mathbb{P}((X_0, \dots, X_k) = w \mid T < \infty, X_T = i)
	\end{align*} 
	Now,
	\begin{align*}
		 & \prob{X_T = x_0, \dots, X_{T+n} = x_n, (X_0, \dots, X_T) = w \mid T < \infty, X_T = i} \\
		 & = \frac{\delta_{i x_0} P(x_0,x_1) \dots P(x_{n-1}, x_n) \prob{(X_0, \dots, X_k) = w \mid T = k, X_k = i}}{\prob{T < \infty, X_T = i}} \\
		 & = \delta_{i x_0} P(x_0,x_1) \dots P(x_{n-1}, x_n) \prob{(X_0, \dots, X_T) = w \mid T < \infty, X_T = i}
	\end{align*}
	as required.
\end{proof}
\begin{example}
	Consider a simple random walk on $I = \mathbb N \cup \{0\}$, where $P(x,x\pm 1) = \frac{1}{2}$ for $x \neq 0$, and $P(0,1) = 1$.
	Now, let $h_i = \psub{i}{T_0 < \infty}$.
	We want to calculate $h_1$.
	We can write
	\begin{align*}
		h_1 = \frac{1}{2} + \frac{1}{2} h_2
	\end{align*}
	but the system of recursion relations this generates is difficult to solve.
	Instead, we will write
	\begin{align*}
		h_2 = \psub{2}{T_0 < \infty}
	\end{align*}
	Note that in order to hit 0, we must first hit 1.
	So conditioning on the first hitting time of 1 being finite, after this time the process starts again from 1.
	Now,
	\begin{align*}
		h_2 = \psub{2}{T_0 < \infty, T_1 < \infty} = \psub{2}{T_0 < \infty \mid T_1 < \infty} \psub{2}{T_1 < \infty}
	\end{align*}
	Conditional on $T_1 < \infty$ and $X_{T_1}$, by the strong Markov property $(X_{T+n})_{n \geq 0}$ is $\Markov{\delta_1, P}$. So we can express (under the conditioning)  $T_0 = T_1 + \widetilde T_0$, where $\widetilde T_0$ is independent of $T_1$\footnote{$X_{T_1 + n}$ is independent of $(X_0, \dots, X_{T_1})$}, with the same distribution as $T_0$ under $\mathbb P_1$.
	Note that
	\begin{align*}
		\psub{2}{T_0 < \infty \mid T_1 < \infty} &= \psub{2}{T_1 + \widetilde T_0 < \infty \mid T_1 < \infty} \\
		&= \psub{2}{\widetilde T_0 < \infty \mid T_1 < \infty} \\
		&= \psub{1}{T_0 < \infty} \\
		&= h_1.
	\end{align*}
	But $\psub{2}{T_1 < \infty} = \psub{1}{T_0 < \infty}$ by translation invariance, so
	\begin{align*}
		h_2 &= \psub{2}{T_1 < \infty} \psub{1}{T_0 < \infty} \\
		&= h_1^2
	\end{align*}
	So $h_1 = \frac{1}{2} + \frac{1}{2}h_2 \implies \frac{1}{2} + \frac{1}{2} h_1^2$ so $h_1 = 1$.
	In general, therefore, for any $n \in \mathbb N$,
	\begin{align*}
		h_n = h_1^n
	\end{align*}
\end{example}