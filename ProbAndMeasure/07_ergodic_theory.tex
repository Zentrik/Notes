\section{Ergodic theory}

\subsection{Laws of Large Numbers}

\begin{proposition}[Weak Law of Large Numbers]
	Let $(X_n)_{n \in \mathbb N}$ be iid s.t. $\expect{X_n} = \mu$ and $\Var{X_n} = \sigma^2 < \infty$.
	Then $\frac{1}{n} \sum_{i=1}^n X_i \to \mu$ in probability as $n \to \infty$.
\end{proposition}

\begin{proof}
	By Chebyshev's inequality,
	\begin{align*}
        \prob{\abs{\frac{1}{n}\sum_{i=1}^n X_i - \mu} > \varepsilon} \leq \frac{1}{n^2 \varepsilon^2} \Var{\sum_{i=1}^n X_i} = \frac{\sigma^2}{n\varepsilon^2} \xrightarrow{n \to \infty} 0
    \end{align*}
	So $\frac{1}{n} \sum_{i=1}^n X_i \to \mu$ in probability.
\end{proof}

This result has several weaknesses, and we can provide stronger results.

\begin{proposition}[Strong Law of Large Numbers]
	Let $(X_n)_{n \in \mathbb N}$ be iid s.t. $\expect{X_n} = \mu < \infty$.
	Then $\frac{1}{n} \sum_{i=1}^n X_i \to \mu$ a.s. as $n \to \infty$.
\end{proposition}

\begin{proposition}
	Let $(X_n)_{n \in \mathbb N}$ be indep with $\expect{X_n} = \mu$ and $\expect{X_n^4} \leq M \ \forall \; n$.
	Then $\frac{1}{n} \sum_{i=1}^n X_i \to \mu$ a.s. as $n \to \infty$.
\end{proposition}

\begin{proof}
	Let $Y_n = X_n - \mu$.
	Then $\expect{Y_n} = 0$, and $\expect{Y_n^4} \leq 2^4 \qty(\expect{X_n^4} + \mu^4) < \infty$.
	So we can assume $\mu = 0$.
	For distinct indices $i, j, k, \ell$, by independence and the Cauchy--Schwarz inequality, we have
	\begin{align*}
        0 = \expect{X_i X_j X_k X_\ell} = \expect{X_i^2 X_j X_j} = \expect{X_i^3 X_j};\quad \expect{X_i^2 X_j^2} \leq \sqrt{\expect{X_i^4}}\sqrt{\expect{X_j^4}} \leq M
    \end{align*}
	So we can compute
	\begin{align*}
		\expect{\qty(\sum_{i=1}^n X_i)^4} = \expect{\sum_{i=1}^n X_i^4} + 6\expect{\sum_{i < j} X_i^2 X_j^2} \leq nM + 3n(n-1)M \leq 3n^2 M
    \end{align*}
	Let $S_n = \sum_{i=1}^n X_i$.
	Then,
	\begin{align*}
		\expect{\qty(\frac{S_n}{n})^4} &\leq \frac{1}{n^4} 3n^2 M \\
        \expect{\sum_{n=1}^\infty \qty(\frac{S_n}{n})^4} &= \sum_{i=1}^{\infty} \expect{\qty(\frac{S_n}{n})} \text{ by MCT} \\
		&\leq \sum_{n=1}^\infty \frac{3M}{n^2} < \infty
    \end{align*}
	Hence $\sum_{n=1}^\infty \qty(\frac{S_n}{n})^4 < \infty$ almost surely.
	But then $\qty(\frac{S_n}{n})^4 \to 0$ almost surely, so $\frac{S_n}{n} \to 0$ almost surely.
\end{proof}

\subsection{Invariants - Measure Preserving Transformations}

Let $(E, \mathcal E, \mu)$ be a $\sigma$-finite measure space.

\begin{definition}[Measure Preserving]
	A measurable map $\Theta \colon E \to E$ is \vocab{measure-preserving} (m.p.) if $\mu \circ \Theta\inv = \mu$, i.e. $\mu(\Theta^{-1}(A)) = \mu(A) \; \forall \; A \in \mathcal E$.
\end{definition}

In this case, for any integrable function $f \in L^1(\mu)$, we have $\int_E f \dd{\mu} = \int_E f \circ \Theta \dd{\mu}$ as $\int_E f \circ \Theta \dd{\mu} = \int_E f \dd{\mu \circ \Theta\inv}$.

\begin{definition}[$\Theta$-Invariant]
	A measurable map $f \colon E \to \mathbb R$ is called \vocab{$\Theta$-invariant} if $f \circ \Theta = f$. \\
	A set $A \in \mathcal E$ is \vocab{$\Theta$-invariant} if $\Theta^{-1}(A) = A$, or equivalently, $1_A$ is $\Theta$-invariant.
\end{definition}

The collection $\mathcal E_\Theta$ of $\Theta$-invariant sets forms a $\sigma$-algebra over $E$.
A function $f \colon E \to \mathbb R$ is invariant iff $f$ is $\mathcal E_\Theta$-measurable (Sheet 4).

\begin{definition}[Ergodic]
	$\Theta$ is called \vocab{ergodic} if the $\mathcal{E}_\Theta$ is $\mu$-trivial, i.e. $\forall \; A \in \mathcal{E}_\Theta$ $\mu(A) = 0$ or $\mu(A^c) = 0$.
\end{definition}

The point is an ergodic transformation mixes the sets well.
Boltzman (1880), Ergodic hypothesis - over long times, a gas particle in some space will ``fill the whole space'', it will be arbitrarily close to any point in the space.
You could imagine a trajectory, $x, \Theta(x), \Theta^2(x), \dots$


For Markov Chains, ergodicity $\iff$ irreducibility.

\begin{fact}
	If $f$ is $\Theta$-invariant, $\Theta$ is ergodic iff $f$ is constant a.s. on $E$ (Sheet 4).
\end{fact}

\begin{proof}
	See Sheet 4.
	We want to show distribution of $f$ is a step function.
	We know $f \in \mathcal{E}_\Theta$ so $\mu(f\inv(-\infty, x)) = 0$ or $\mu(f\inv[x, \infty)) = 0$.
	Hence $f$ is constant. % with the constant being the sup of the $x$ s.t. $\mu(f\inv(-\infty, x)) = 0$.
\end{proof}

\begin{example}
	Consider $(E, \mathcal E) = ((0,1], \mathcal B)$ with the Lebesgue measure $\mu$.
	The maps $\Theta_a(x) = x + a$ modulo 1 and $\Theta(x) = 2x$ modulo 1 are both m.p., and ergodic unless $a \in \mathbb Q$ (Sheet 4).
\end{example}

\subsection{Ergodic theorems}
\begin{lemma}[Maximal Ergodic Lemma] \label{lem:max}
    Let $(E, \mathcal E, \mu)$ be a $\sigma$-finite measure space.
	Let $\Theta \colon E \to E$ be m.p..
	For $f \in L^1(\mu)$, we define $S_0(f) = 0$ and $S_n(f) = \sum_{k=0}^{n-1} f \circ \Theta^k$.
    Let $S^\star = S^\star(f) = \sup_{n \geq 0} S_n(f)$.
    Then $\int_{\qty{S^\star > 0}} f \dd{\mu} \geq 0$.
\end{lemma}

\begin{proof}
    Define $S_n^\star = \max_{k \leq n} S_k$.
    Then clearly $S_n^\star \uparrow S^\star$, and $S_k \leq S_n^\star$ for all $k \leq n$.
    Note that for $m \leq n+1$, $S_m = S_{m-1} \circ \Theta + f \leq S_n^\star \circ \Theta + f$.

    Define $A_n = \qty{S_n^\star > 0}$.
    On $A_n$, we have
    \begin{align*}
        S_n^\star = \max_{1 \leq k \leq n} S_k \leq \max_{1 \leq k \leq n+1} S_k \leq S_n^\star \circ \Theta + f
    \end{align*}
    since $S_0 = 0$.
    We can integrate this inequality to find
    \begin{align*}
        \int_{A_n} S_n^\star \dd{\mu} \leq \int_{A_n} S_n^\star \circ \Theta \dd{\mu} + \int_{A_n} f \dd{\mu}
    \end{align*}
    On $A_n^c$, we must have $S_n^\star = 0 \leq S_n^\star \circ \Theta$.
    Hence,
    \begin{align*}
        \int_E S_n^\star \dd{\mu} \leq \int_E S_n^\star \circ \Theta \dd{\mu} + \int_{A_n} f \dd{\mu}
    \end{align*}
    Since $\Theta$ is m.p.,
    \begin{align*}
        \int_E S_n^\star \dd{\mu} \leq \int_E S_n^\star \dd{\mu} + \int_{A_n} f \dd{\mu}
    \end{align*}
    so we obtain (as $S_n^\star \in L_1$)
    \begin{align*}
        \int_{A_n} f \dd{\mu} \geq 0 \quad \forall \; n.
    \end{align*}

	$A_n = \qty{S_n^\star > 0} = \qty{\max_{0 \leq m \leq n} S_m > 0} = \bigcup_{m = 0}^n \qty{S_m > 0} \uparrow \bigcup_{m = 0}^\infty \qty{S_m > 0} = \qty{\sup S_m > 0} = S^\star$. \\
	Hence, $1_{A_n} \to 1_{S^\star > 0}$ and so $f 1_{A_n} \to f 1_{\qty{S^\star > 0}}$ pointwise, and $\abs{f 1_{A_n}} \leq \abs{f} \in L^1(\mu)$, by DCT
    \begin{align*}
        \int_{\qty{S^\star > 0}} f \dd{\mu} = \lim_{n \to \infty} \int_{A_n} f \dd{\mu} \geq 0
    \end{align*}
    as required.
\end{proof}

\begin{remark}
	Let $\mu$ be a finite measure.
	Then for $f \in L^1$ and any $\alpha > 0$, define $\overline S_k = \frac{S_k(f)}{k}$ and $\overline S^\star = \sup_{k \geq 0} \overline S_k$, then
	\begin{align*}
		\mu\qty(\overline S^\star > \alpha) \leq \frac{1}{\alpha} \int_{\overline S^\star > \alpha} f \dd{\mu} \leq \frac{1}{\alpha} \int_E \abs{f} \dd{\mu}.
	\end{align*}
\end{remark}

\begin{proof}
	Proof is left as an exercise, follows from shifting $f$ by $\alpha$ and then applying the maximal ergodic theorem.
\end{proof}

\begin{exercise}
	For $\mu$ a prob measure and $f \in L^1(\mu)$, show that $\qty{\frac{S_n(f)}{n} : n \in \mathbb{N}}$ is UI.
	Hence $\frac{S_n(f)}{n} \to \overline f$ in $L^1$ by Birkhoff's.
	If $\Theta$ is ergodic, then $\overline f = \int f \dd{\mu}$ a.s..
\end{exercise}

\begin{theorem}[Birkhoff's Ergodic Theorem]
	Let $(E, \mathcal E, \mu)$ be a $\sigma$-finite measure space.
	Let $\Theta \colon E \to E$ be m.p..
	For $f \in L^1(E, \mathcal{E}, \mu)$, we define $S_0 = 0$ and $S_n = S_n(f) = \sum_{k=0}^{n-1} f \circ \Theta^k$.
	Then $\exists$ a $\Theta$-invariant integrable fcn $\overline f \in L^1(E, \mathcal{E}, \mu)$ with $\mu\qty(\abs{\overline f}) \leq \mu(\abs{f})$ s.t. $\frac{S_n(f)}{n} \to \overline f$ a.e. as $n \to \infty$.
\end{theorem}

\begin{remark}
	If $\Theta$ ergodic, $\hat{f}$ is constant a.e..

	Relating back to the gas example, $x, \Theta(x), \dots$ is the trajectory of a gas particle.
	Then $\frac{S_n(f)}{n}$ is the average of $f$ along the trajectory (time average).
	Then $\overline f$ is the average of $f$ over the whole space.
\end{remark}

The proof of Birkhoff's ergodic theorem is non-examinable.

\begin{proof}[Proof (non-examinable)]
	Since $\mu(\abs{f \circ \Theta^{n-1}}) = \mu(\abs{f})$, we have $\mu(\abs{S_n}) \leq n \mu(\abs{f})$ and thus by Fatou's
    \begin{align*}
        \mu\qty(\abs{\overline f}) = \mu\qty(\liminf_n \abs{\frac{S_n}{n}}) \leq \liminf_n \mu\qty(\abs{\frac{S_n}{n}}) \leq \mu(\abs{f}).
    \end{align*}

    Note that
    \begin{align*}
		\frac{S_n \circ \Theta}{n} &= \frac{S_{n+1} - f}{n + 1} \frac{n + 1}{n} \\
        \text{So, } \limsup_n \frac{S_n \circ \Theta}{n} &= \limsup_n \frac{S_{n+1}}{n+1} = \limsup_n \frac{S_n}{n}
    \end{align*}
    and the same holds for $\liminf_n$.
    Hence $\limsup_n \frac{S_n}{n}$ and $\liminf_n \frac{S_n}{n}$ are invariant functions.
    So they are $\mathcal E_\Theta$-measurable.
    Hence
    \begin{align*}
        D = D_{a,b} = \qty{\liminf_n \frac{S_n}{n} < a < b < \limsup_n \frac{S_n}{n}}
    \end{align*}
    are measurable and invariant sets.

	It suffices to show that $\mu(D) = 0$.
	As letting $\Delta = \qty{\liminf \qty(\frac{S_n}{n}) < \limsup \qty(\frac{S_n}{n})} = \bigcup_{a < b \in \mathbb{Q}} D_{a, b}$.
	Hence if $\mu(D) = 0 \implies \mu\qty(\bigcup_{a < b \in \mathbb{Q}} D_{a, b}) = 0 \implies \mu(\Delta) = 0$.
	Define,
	\begin{align*}
		\overline f = \begin{cases}
			\liminf \frac{S_n}{n} = \limsup \frac{S_n}{n} & x \in \Delta^c \\
			0 & x \in \Delta
		\end{cases}
	\end{align*}
	then $S_n/n \to \overline f$ $\mu$-a.e. and $\overline f$ is $\Theta$ invariant (as $\liminf \frac{S_n}{n}$ and $\Delta$ are $\Theta$-invariant).

	Fix $a < b$.
	Note that $\Theta : D \to D$ by invariance and $\Theta$ is $\mu \mid_D$-measure preserving as
	\begin{align*}
        \eval{\mu}_D(A) &= \mu(A \cap D) = \mu(\Theta^{-1}(A \cap D)) = \mu(\Theta^{-1}(A) \cap \Theta^{-1}(D)) \\
		&= \mu(\Theta^{-1}(A) \cap D) = \eval{\mu}_D(\Theta^{-1}(A))
    \end{align*}
	Also either $b > 0$ or $a < 0$ (if $a < 0$ change $f$ to $-f$ and $a$ to $-b$, then $b = -a > 0$).
	So assume $b > 0$ wlog.

	We will apply the \nameref{lem:max} with $E = D$ and $\mu = \eval{\mu}_D$.
    Let $B \in \mathcal E$, where $B \subseteq D$ s.t. $\mu(B) < \infty$.
    Let $g = f - b 1_B \in L^1(\mu)$.
    Then,
    \begin{align*}
        S_n(g) = S_n(f) - bS_n(1_B) \geq S_n - bn
    \end{align*}
    which is positive on $D$ for some $n$ by the definition of $\limsup_n$.
	Hence, $S^\star(g) = \sup_{n \geq 0} S_n(g) > 0$ on $D$.

    % Note that $\qty{S^\star > 0} \subseteq D$ as we restrict our measure space to $D$, but by the previous inequality, $S^\star > 0$ on $D$.
    So $D = \qty{S^\star > 0} \cap D$.
    Then by the \nameref{lem:max} on $D$,
    \begin{align*}
        0 \leq \int_{D \cap \qty{S^\star > 0}} g \dd{\mu} = \int_D g \dd{\mu} = \int_D f \dd{\mu} - b \mu(B)
    \end{align*}
    Hence, $b \mu(B) \leq \int_D f \dd{\mu}$.

    By $\sigma$-finiteness, this inequality extends to $D$; $\exists$ measurable sets $B_n \uparrow D$ where $\mu(B_n) < \infty$.
	Hence taking limits, $b\mu(D) = b \lim_n \mu(B_n) \leq \int_D f \dd{\mu}$.
	Thus $\mu(D) < \infty$ as $f \in L^1$. \\
    Repeating a similar arguments to above\footnote{Now however we take $D$ instead of $B$ and $g' = -f - (-a) 1_D$. On $D$, $S_n(g') = S_n(-f) - (-a) S_(1_D) = S_n(-f) - (-a) n 1_D = S_n(-f) - (-a)n$ as $D$ is $\Theta$ invariant, i.e. $S_n(1_D) = 1_D$.} for $-f$ and $-a$, we obtain $-a\mu(D) \leq \int_D -f \dd{\mu}$.
    Combining these two inequalities gives
    \begin{align*}
        b\mu(D) \leq \int_D f \dd{\mu} \leq a\mu(D)
    \end{align*}
    But $a < b$ and $\mu(D) < \infty$, so $\mu(D) = 0$.
\end{proof}

\begin{theorem}[von Neumann's $L^p$ ergodic theorem]
	Let $\mu(E) < \infty$ and $1 \leq p < \infty$.
	Then for $f \in L^p(\mu)$, $\frac{S_n(f)}{n} \to \overline f$ in $L^p$ as $n \to \infty$.
\end{theorem}

\begin{proof}
	Since $\Theta$ is m.p., we have
	\begin{align*}
        \norm{f \circ \Theta^n}_p^p = \int_E \abs{f}^p \circ \Theta^n \dd{\mu} = \int_E \abs{f}^p \dd{\mu} = \int_E \abs{f}^p \dd{\mu} = \norm{f}_p^p
    \end{align*}
	Thus, by Minkowski's inequality, for all $f \in L^p$ we have
	\begin{align*}
        \norm{\frac{S_n(f)}{n}}_p \leq \frac{1}{n} \sum_{i=0}^{n-1} \norm{f \circ \Theta^i}_p = \norm{f}_p
    \end{align*}
	So $\frac{S_n(f)}{n}$ is a contraction in $L^p$.
	For each $K > 0$, we define $f_K = \max(\min(f, K), -K)$.
	Then
	\begin{align*}
        \norm{f - f_K}_p^p = \int_E \abs{f - f_K}^p 1_{\abs{f} > K} \dd{\mu}
    \end{align*}
	Since $1_{\abs{f} > K} \to 0$ pointwise, and $\abs{f - f_K} \leq 2\abs{f}^p \in L^1$, we find $\norm{f - f_K}_p < \frac{\varepsilon}{3}$ by DCT, for sufficiently large $K = K_\varepsilon$.

	As $\abs{f_K} \leq K$, we have $\abs{\frac{S_n(f_K)}{n}} \leq K$.
	Since $\mu$ is finite, $f_K \in L^1(\mu)$, so by Birkhoff's ergodic theorem, $\frac{S_n(f_K)}{n} \to \overline f_K$ a.e. for some invariant $\overline f_K \in L^1$.
	Note that $\overline f_k$ is bounded by $K$ as $\frac{S_n(f_K)}{n}$ is bounded by $K$.
	By the bounded convergence theorem, we deduce that $\norm{\frac{S_n(f_K)}{n} - \overline f_K} \to 0$ as $n \to \infty$.
	Further, this holds in $L^p$ since
	\begin{align*}
        \norm{\frac{S_n(f_K)}{n} - \overline f_K}_p \leq (2K)^{\frac{p-1}{p}} \norm{\frac{S_n(f_K)}{n} - \overline f_K}_1 < \frac{\varepsilon}{3}
    \end{align*}
	where the last inequality holds for sufficiently large $n$.
	Since $\mu$ is a finite measure, $L^p(\mu) \subseteq L^1(\mu)$, hence by Birkhoff's ergodic theorem, $\frac{S_n(f)}{n} \to \overline f$ a.e. as $f \to \infty$.
	Then, by the contraction property applied to $f - f_K$,
	\begin{align*}
		\norm{\overline f - \overline f_K}_p^p &= \int_E \abs{\overline f - \overline f_K}^p \dd{\mu} \\
		&= \int_E \liminf_n \abs{\frac{S_n(f) - S_n(f_K)}{n}}^p \dd{\mu} \\
		&\leq \liminf_n \int_E \abs{\frac{S_n(f) - S_n(f_K)}{n}}^p \dd{\mu} \quad \text{by Fatou} \\
		&= \liminf_n \int_E \abs{\frac{S_n(f - f_K)}{n}}^p \dd{\mu} \\
		&= \liminf_n \norm{\frac{S_n(f - f_K)}{n}}_p^p \\
		&\leq \liminf_n \norm{f - f_K}_p^p \quad \text{shown earlier by Minkowski}\\
		&= \norm{f - f_K}_p^p < \qty(\frac{\varepsilon}{3})^p
	\end{align*}
	So in particular, $\overline f \in L^p$.
	Then by Minkowski,
	\begin{align*}
			\norm{\frac{S_n(f)}{n} - \overline f}_p &\leq \norm{\frac{S_n(f) - S_n(f_K)}{n}}_p + \norm{\frac{S_n(f_K)}{n} - \overline f_K}_p + \norm{\overline f - \overline f_K}_p \\
			&< \norm{\frac{S_n(f) - S_n(f_K)}{n}}_p + \frac{2\varepsilon}{3} \\
			&\leq \norm{f - f_K}_p + \frac{2\varepsilon}{3} = \varepsilon
	\end{align*}
	for sufficiently large $n$.
\end{proof}

\begin{remark} \label{rem:ergodic} \
	\begin{enumerate}
		\item If $\mu$ a prob measure and $\Theta$ ergodic, then $\bar f$ is a constant a.s., so $\bar f = \int \bar f \dd{\mu}$.
		Also, $\int f \dd{\mu} = \int \frac{S_n(f)}{n} \dd{\mu} \to \int \bar f \dd{\mu} \; \forall \; n$.
		Hence $\int \bar f \dd{\mu} = \int f \dd{\mu}$. \\
		Then, $\frac{S_n(f)}{n} \xrightarrow{n \to \infty} \mathbb{E}[f]$ $\mu$ a.s. and in $L^1$.
		\item For $\Theta$ m.p. and $f \in L^1$, $\frac{S_n(f)}{n} \xrightarrow{\mu a.s and L^1} \mathbb{E}[f \mid \mathcal{E}_\Theta]$.
		For $f \in L^2$, $\mathbb{E}[f \mid \mathcal{E}_\Theta]$ is (a version of) the projection of $f$ on $L^2(\mathcal{E}_\Theta)$.
	\end{enumerate}
\end{remark}

\subsection{Infinite product spaces}
Let $E = \mathbb R^{\mathbb N} = \qty{x = (x_n)_{n \in \mathbb N}}$ be the space of real sequences.
Consider
\begin{align*}
        \mathcal C = \qty{A = \prod_{n=1}^\infty A_n : A_n \in \mathcal B, \exists N \in \mathbb N, \forall n > N, A_n = \mathbb R}
    \end{align*}
This forms a $\pi$-system, which generates the \emph{cylindrical $\sigma$-algebra} $\sigma(\mathcal C)$.
We can show that $\sigma(\mathcal C) = \sigma(\qty{f_n : n \in \mathbb N})$ where $f_n(x) = x_n$ are the coordinate projection functions on $E$.
We can also show $\sigma(\mathcal C) = \mathcal B(\mathbb R^{\mathbb N})$ for the product topology or the topology of pointwise convergence.

Let $(X_n)_{n \in \mathbb N}$ be a sequence of iid r.v.s defined on $(\Omega, \mathcal F, \mathbb P)$ with common law $\mu_{X_n} = m$ for all $n$; this exists by an earlier theorem.
We define a map $X \colon \Omega \to E$ by $X(\omega) = (X_1(\omega), X_2(\omega), \dots)$.
This is $\mathcal F$--$\sigma(\mathcal C)$ measurable, since for all $A \in \mathcal C$, we have
\begin{align*}
        X^{-1}(A) = \qty{\omega : X_1(\omega) \in A_1, \dots, X_N(\omega) \in A_N} = \bigcap_{n=1}^N X_n^{-1}(A_n) \in \mathcal F
    \end{align*}
We denote $\mu = \mathbb P \circ X^{-1}$, which is the unique product prob measure in $E$ satisfying
\begin{align*}
		\mu\qty(\prod_{n=1}^\infty A_n) &= \lim_{N \to \infty} \mu\qty(\prod_{n=1}^N A_n) \\
		&= \lim_{N \to \infty} \prob{X_1 \in A_1, \dots, X_N \in A_N} \\
		&= \lim_{N \to \infty} \prob{X_1 \in A_1} \cdots \prob{X_N \in A_N} \\
		&= \prod_{n=1}^\infty \prob{X_n \in A_n} \\
		&= \prod_{n=1}^\infty m(A_n)
\end{align*}
Note that we need to use finiteness of $N$ to exploit independence of the $X_i$.
We call $(E, \mathcal E, \mu) = (\mathbb R^{\mathbb N}, \sigma(\mathcal C), m^{\mathbb N})$ the \emph{canonical model} for an infinite sequence of iid r.v.s of law $m$.

\begin{definition}[Shift Map]
	The shift map $\Theta \colon E \to E$ is defined by $\Theta(x_1, x_2, \dots) = (x_2, x_3, \dots)$.
\end{definition}

\begin{theorem}
	On $(E, \mathcal{E}, \mu)$, the shift map $\Theta$ is measurable, m.p. and ergodic.
\end{theorem}

\begin{proof}
	Measurability is obvious.

	For $A \in \mathcal C$,
	\begin{align*}
			\mu(A) &= \prob{X_1 \in A_1, \dots, X_N \in A_N} \\
			&= \prob{X_1 \in A_1} \cdots \prob{X_N \in A_N} \\
			&= \prod_{n=1}^N m(A_n) \\
			&= \prob{X_2 \in A_1} \cdots \prob{X_{N+1} \in A_N} \\
			&= \mu(\Theta^{-1}(A))
	\end{align*}
	so $\Theta$ is m.p. as m.p. on $\pi$-system $\mathcal{C}$.

	Recall that the tail $\sigma$-algebra is defined by $\mathcal T = \bigcap_n \mathcal T_n$ where $\mathcal T_n = \sigma(X_{n+1}, X_{n+2}, \dots) = \sigma(f_{n+1}, f_{n+2}, \dots)$.
	Note that for all $A \in \mathcal C$, we have
	\begin{align*}
        \Theta^{-n}(A) &= \mathbb{R}^n \times A_1 \times A_2 \times \dots \\
		&= \qty{x \in \mathbb R^{\mathbb N} : (x_{n+1}, x_{n+2}, \dots) \in A} \in \mathcal T_n
    \end{align*}
	Now, if $A$ is invariant, $A = \Theta^{-n}(A) \in \mathcal T_n \; \forall \; n$, so $A \in \mathcal T$.
	By Kolmogorov's zero-one law as $(X_i)$ iid, $\mu(A) = 0$ or $\mu(A) = 1$ as required for ergodicity.
\end{proof}
We can apply Birkhoff's ergodic theorem to $\Theta$.
If $f \in L^1(\mu)$, then $\frac{S_n(f)}{n} \to \overline f \in L^1(\mu)$ almost surely.
Since $\overline f$ is invariant and $\Theta$ is ergodic, $\overline f$ is almost surely constant.
By von Neumann's $L^p$-ergodic theorem, convergence holds in fact in $L^1$.

\subsection{Strong law of large numbers}

\begin{theorem} \label{thm:canonical}
	Let $m$ be a prob measure on $\mathbb{R}$ s.t. $\int_{\mathbb R} \abs{x} \dd{m(x)} < \infty$ and $\int_{\mathbb R} x \dd{m(x)} = \nu$.
	Let $(E, \mathcal{E}, \mu)$ be the canonical model where the coordinate maps $f_n(x) = x_n$ are iid with law $m$.
	Then
	\begin{align*}
        \mu\qty(\qty{x \in \mathbb R^{\mathbb N} : \frac{x_1 + x_2 + \dots + x_n}{n} \to \nu}) = 1
    \end{align*}
\end{theorem}

\begin{proof}
	Let $\Theta : E \to E$ be the shift map $\Theta(x_1, x_2, \dots) = (x_2, x_3, \dots)$.
	It is m.p. and ergodic by previous thm.
	Consider $f : E \to \mathbb{R}$ as $f(x) = x_1$.
	Then $f \in L^1(\mu)$, since $\int_E \abs{f} \dd{\mu} = \int_{\mathbb{R}} \dd{\mu \circ f\inv(x)} = \int_{\mathbb R} \abs{x_1} \dd{m(x_1)} < \infty$.
	So by Birkhoff and von-Neumann, as $\Theta$ ergodic, by \cref{rem:ergodic}, $\frac{S_n(f)}{n} = \frac{x_1 + \dots + x_n}{n} \to \bar f = \int f \dd{\mu} = \int_{\mathbb R} x_1 \dd{m(x_1)} = \nu$ $\mu$ a.s.
\end{proof}

\begin{theorem}[Kolmogorov SLLN (1930)]
	Let $(X_n)_{n \in \mathbb N}$ be iid r.v.s s.t. $\expect{\abs{X_1}} < \infty$.
	Then $\frac{1}{n} \sum_{i=1}^n X_i \to \expect{X_1}$ almost surely.
\end{theorem}

\begin{proof}
	Let $m$ be the law of $X_n$, $\nu = \mathbb{E}[X_1]$ and $\mu = \mathbb{P} \circ X\inv$ where $X : \Omega \to E = \mathbb{R}^\mathbb{N}$ is $X(\omega) = (X_1(\omega), X_2(\omega), \dots)$.
	Then apply \cref{thm:canonical},
	\begin{align*}
        \prob{\frac{1}{n} \sum_{i=1}^n X_i \to \expect{X_1}} = \mu\qty(\qty{ x : \frac{x_1 + \dots + x_n}{n} \to \nu }) = 1
    \end{align*}
\end{proof}

\begin{remark}
	The hypothesis $\expect{\abs{X}} < \infty$ cannot be weakened; we see on an example sheet that $\frac{1}{n} \sum_{i=1}^n X_i$ can exhibit various behaviours.
	Note that this notion of convergence is stronger than the weak convergence seen in the central limit theorem.
	The law of the iterated logarithm is that
	\begin{align*}
        \limsup_n \frac{X_1 + \dots + X_n}{\sqrt{2 n \log \log n}} = 1
    \end{align*}
	almost surely, and $-1$ for the limit inferior.
	In particular, the central limit theorem does not hold almost surely.
\end{remark}

\begin{corollary}
	By von Neumann's ergodic theorem, in the strong law of large numbers, we have $\expect{\abs{\frac{1}{n} \sum_{i=1}^n X_i - \expect{X}}} \to 0$ as $n \to \infty$.
\end{corollary}

\begin{aside}{Aside}
	\begin{enumerate}
		\item If $(\mu_n)$ is a sequence in $\mathbb{R}^n$ of prob measures that converges weakly to $\mu$, then $(\mu_n)$ is ``tight'', i.e. $\forall \; \epsilon > 0$, $\exists$ a compact set $K$ s.t. $\mu_n(K^c) < \epsilon \; \forall \; n$.
		\item If $(\mu_n)$ a sequence of prob measures that are tight, then $\exists$ a subsequence $(n_k)$ and a prob measure $\mu$ s.t. $\qty(\mu_{n_k}) \to \mu$ weakly (Prokhorov's  thm or Banach-Alaoglu thm).
		\item If distributions $F_n \xrightarrow{d} F$, then $\exists$ a prob space s.t. $\mu_{X_n}$ is $F_n$ and $X_n \to X$ a.s..
		\item If $X_n \xrightarrow{d} X$ and $Y_n \xrightarrow{d} Y$ then $X_n + Y_n \not\to X + Y$, in fact $X, Y$ are not necessarily even defined in the same prob space so $X + Y$ doesn't even make sense. \\
		However, if $X_n \xrightarrow{d} X$ and $Y_n \xrightarrow{\mathbb{P}} c$, where $c$ is a constant.
		Then $(X_n, Y_n) \to (X, c)$ so by continuous mapping thm $X_n + Y_n \xrightarrow{d} X + c$ (Slutsky's thm). \\
		This is quite useful in stats where with CLT if variance is unknown we can replace it with std deviation which converges to the true value a.s. and hence in $\mathbb{P}$.
	\end{enumerate}
\end{aside}